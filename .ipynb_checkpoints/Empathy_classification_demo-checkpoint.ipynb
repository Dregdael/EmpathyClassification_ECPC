{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d0a22c-4c57-42ec-9fd1-acccab9a2cc7",
   "metadata": {},
   "source": [
    "# DEMO: Empathy classification using a pattern classifier\n",
    "\n",
    "In this notebook, it is possible to use a previously trained contrast-pattern classification algorithm to obtain the empathy level of a conversation between two people. \n",
    "\n",
    "A conversation prompt is presented, pulled from the EmpatheticExchanges database subset for testing classification algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6c48750-894d-4cfa-b690-743951e0d5e6",
   "metadata": {},
   "source": [
    "## Setup \n",
    "\n",
    "This subsection focuses on setting up the environment, functions, utilities, and models required for the demo. Likewise, it is where the variables are manually declared. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d243c2-35f2-4a20-a573-6142fc14b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import re\n",
    "#import classifier\n",
    "from PBC4cip import PBC4cip\n",
    "from PBC4cip.core.Evaluation import obtainAUCMulticlass\n",
    "from PBC4cip.core.Helpers import get_col_dist, get_idx_val\n",
    "\n",
    "#utilities for database management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import train_classifier as trainer\n",
    "import test_classifier as tester\n",
    "import database_processing_package as data_processer\n",
    "\n",
    "#relevant classifiers for annotating exchange feature\n",
    "from classifiers.empathetic_intent import intent_prediction as ip\n",
    "from classifiers.sentiment import sentiment_prediction as sp\n",
    "from classifiers.epitome_mechanisms import epitome_predictor as epitome\n",
    "from classifiers.nrc_vad_lexicon import lexicon_analysis as lexicon\n",
    "from classifiers.course_grained_emotion import pretrained_32emotions as em32\n",
    "from classifiers.course_grained_emotion import emotion_reductor as em_red\n",
    "import database_processing_package as data_processer\n",
    "\n",
    "from spellchecker import SpellChecker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d9ab96-e4aa-47e5-b4f4-5face72f158e",
   "metadata": {},
   "source": [
    "### Selection of features\n",
    "\n",
    "In this cell, we define the model that will be used for this task. We declare its location directory, and its name \"trained_pbc4cip.sav\" \n",
    "\n",
    "Likewise, we declare a \"feature vector\" which contains binary flags for the features used by the model to predict empathy. \n",
    "\n",
    "Finally, we declare the database from which the prompts will be extracted from by declaring its directory. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74aab462-ebf7-495c-ba30-168b3f718f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relevant directories\n",
    "current_dir = os.getcwd() #get directory of the repository\n",
    "#Select an appropriate classification model in the Experiments folder\n",
    "model_directory = current_dir + '/Experiments/outputs/Experiment '+ str(70) + '/' + 'trained_pbc4cip.sav'\n",
    "\n",
    "\n",
    "feature2number = {'database_to_classify':0,'intent' : 1, 'sentiment' : 2, 'epitome':3, 'VAD_vectors':4, 'utterance_length':5,\n",
    "                  '32_emotion_labels':6,'20_emotion_labels':7, \n",
    "                  '8_emotion_labels':8, 'emotion_mimicry':9, 'Reduce_empathy_labels':10, \n",
    "                  'exchange_number' : 11}\n",
    "\n",
    "feature_vector = [1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1]\n",
    "'''\n",
    "                 [1,#database to pull from 0 = empatheticconversations (old), 1 empatheticexchanges (new)\n",
    "                  1,#intent\n",
    "                  1,#sentiment\n",
    "                  0,#epitome\n",
    "                  1,#vad lexicon\n",
    "                  1,#length\n",
    "                  0,#emotion 32\n",
    "                  0,#emotion 20\n",
    "                  1,#emotion 8\n",
    "                  1,#emotion mimicry\n",
    "                  1, #reduce empathy labels\n",
    "                  1 #exchange number\n",
    "                  ]\n",
    "'''\n",
    "\n",
    "if feature_vector[feature2number['database_to_classify']] == 1: \n",
    "    database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges_test.csv'\n",
    "else: \n",
    "    database_dir = '/processed_databases/EmpatheticConversationsExchangeFormat/EmpatheticConversations_ex.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8548e12f-e577-4f23-b177-d4273c9def5b",
   "metadata": {},
   "source": [
    "### Loading classification models\n",
    "\n",
    "In this cell, we prepare the classification models for obtaining empathy-related features. These models must be pretrained before they are loaded by this demo. \n",
    "\n",
    "### WARNING: DO NOT RUN THIS TWICE. It will cause memory errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e6768f2-4db7-4bb2-87b7-d0b7b391a930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load intent model\n",
    "if feature_vector[feature2number['intent']] == 1: \n",
    "    empIntSubDir = './classifiers/empathetic_intent/'\n",
    "    model_intent,tokenizer_intent,device = ip.loadModelTokenizerAndDevice(empIntSubDir) #get model and parameters\n",
    "#load sentiment model\n",
    "if feature_vector[feature2number['sentiment']] == 1: \n",
    "    empIntSubDir = './classifiers/empathetic_intent/'\n",
    "    sent_model, sent_tokenzr = sp.loadSentimentModel() #get model and tokenizer\n",
    "#epitome model is loaded during inference due to the code of its classifier\n",
    "if feature_vector[feature2number['epitome']] == 1:\n",
    "    epitome_empathy_classifier = epitome.load_epitome_classifier('classifiers/epitome_mechanisms/trained_models')\n",
    "#load lexicon\n",
    "if feature_vector[feature2number['VAD_vectors']] == 1:\n",
    "    lexicon_df, wnl, stp_wrds = lexicon.setup_lexicon('classifiers/nrc_vad_lexicon/BipolarScale/NRC-VAD-Lexicon.txt')\n",
    "#load emotion classifier with 32 labels for any of the emotion labels options\n",
    "if (feature_vector[feature2number['32_emotion_labels']] == 1) or (feature_vector[feature2number['20_emotion_labels']] == 1) or (feature_vector[feature2number['8_emotion_labels']] == 1):\n",
    "    emo32_model, emo32_tokenzr = em32.load32EmotionsModel() #get model and tokenizer\n",
    "#it is necessary to get the VAD vectors for obtaining emotion mimicry\n",
    "if feature_vector[feature2number['emotion_mimicry']] == 1:\n",
    "    lexicon_df, wnl, stp_wrds = lexicon.setup_lexicon('classifiers/nrc_vad_lexicon/BipolarScale/NRC-VAD-Lexicon.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08573e51-15fc-4461-b8a6-65f7ca8a13a7",
   "metadata": {},
   "source": [
    "### Definition of data processing function\n",
    "\n",
    "This is a function used to transform a text exchange into the format necessary for classification. It adds the following features: \n",
    "\n",
    "* Sentiment\n",
    "* EPITOME mechanisms (Sharma, 2019)\n",
    "* Valence, Arousal, and Dominance emotion vectors\n",
    "* Utterance lengths for both participants\n",
    "* Emotion labels\n",
    "* Empathetic Intent\n",
    "* Whether there is emotion mimicry\n",
    "\n",
    "This features are dependent on the feature vector defined at the start of this notebook\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0a2ab89d-2d9d-433e-92d4-43c7f1de60c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_answer(sample_df,control_vector):\n",
    "    print('processing data....')\n",
    "    if control_vector[feature2number['sentiment']] == 1: \n",
    "        sample_df['speaker_sentiment'] = sample_df.apply(data_processer.get_sentiment_probabilities,axis = 1, args = (sent_model,sent_tokenzr,'speaker_utterance')) \n",
    "        sample_df[['s_negative','s_neutral', 's_positive']] = pd.DataFrame(sample_df.speaker_sentiment.tolist(),index = sample_df.index)\n",
    "        sample_df['listener_sentiment'] = sample_df.apply(data_processer.get_sentiment_probabilities,axis = 1, args = (sent_model,sent_tokenzr,'listener_utterance')) \n",
    "        sample_df[['l_negative','l_neutral', 'l_positive']] = pd.DataFrame(sample_df.listener_sentiment.tolist(),index = sample_df.index)\n",
    "        sample_df = sample_df.drop(columns=['speaker_sentiment','listener_sentiment'])\n",
    "    if control_vector[feature2number['epitome']] == 1:\n",
    "        sample_df = epitome.classify_epitome_values(epitome_empathy_classifier, sample_df)\n",
    "    if control_vector[feature2number['VAD_vectors']] == 1:\n",
    "        sample_df['vad_speaker'] = sample_df['speaker_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "        sample_df['vad_listener'] = sample_df['listener_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "        sample_df[['valence_speaker','arousal_speaker','dominance_speaker']] = pd.DataFrame(sample_df.vad_speaker.tolist(),index = sample_df.index)\n",
    "        sample_df[['valence_listener','arousal_listener','dominance_listener']] = pd.DataFrame(sample_df.vad_listener.tolist(),index = sample_df.index)\n",
    "        sample_df = sample_df.drop(columns = ['vad_speaker','vad_listener'])\n",
    "    if control_vector[feature2number['utterance_length']] == 1:\n",
    "        sample_df['s_word_len'] = sample_df['speaker_utterance'].apply(data_processer.get_word_len) \n",
    "        sample_df['l_word_len'] = sample_df['listener_utterance'].apply(data_processer.get_word_len) \n",
    "    if (control_vector[feature2number['32_emotion_labels']] == 1) or (control_vector[feature2number['20_emotion_labels']] == 1) or (control_vector[feature2number['8_emotion_labels']] == 1):\n",
    "        sample_df['speaker_emotion'] = sample_df.apply(data_processer.get_emotion_label,axis = 1, args = (emo32_model,emo32_tokenzr,'speaker_utterance')) \n",
    "        sample_df['listener_emotion'] = sample_df.apply(data_processer.get_emotion_label,axis = 1, args = (emo32_model,emo32_tokenzr,'listener_utterance')) \n",
    "        if (control_vector[feature2number['20_emotion_labels']] == 1): \n",
    "            sample_df = em_red.reduce_emotion_labels('speaker_emotion',sample_df)\n",
    "            sample_df = em_red.reduce_emotion_labels('listener_emotion',sample_df)\n",
    "        if (control_vector[feature2number['8_emotion_labels']] == 1): \n",
    "            sample_df = em_red.reduce_emotion_labels_to_8('speaker_emotion',sample_df)\n",
    "            sample_df = em_red.reduce_emotion_labels_to_8('listener_emotion',sample_df)\n",
    "    if control_vector[feature2number['intent']] == 1: \n",
    "        sample_df['utterance'] = str(answer)\n",
    "        sample_df['is_response'] = 1\n",
    "        sample_df['empathetic_intent'] = sample_df.apply(data_processer.get_emp_intent_probabilities, axis=1, args = (model_intent,tokenizer_intent,device,'utterance'))\n",
    "        sample_df[data_processer.intent_labels] = pd.DataFrame(sample_df.empathetic_intent.tolist(),index = sample_df.index)\n",
    "        sample_df = sample_df.drop(columns=['empathetic_intent','utterance','is_response'])\n",
    "    if control_vector[feature2number['emotion_mimicry']] == 1:\n",
    "        if(control_vector[4] == 1):\n",
    "            #get the emotional similarity, if it is more than 0.7 set mimicry to 1\n",
    "            sample_df['emotional_similarity'] = sample_df.apply(data_processer.get_cosine_similarity,axis = 1) \n",
    "            sample_df['mimicry'] = sample_df.apply(lambda x: 1 if x['emotional_similarity'] > 0.7 else 0, axis = 1)\n",
    "            sample_df = sample_df.drop(columns = ['emotional_similarity'])\n",
    "        else: \n",
    "            sample_df['vad_speaker'] = sample_df['speaker_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "            sample_df['vad_listener'] = sample_df['listener_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "            sample_df[['valence_speaker','arousal_speaker','dominance_speaker']] = pd.DataFrame(sample_df.vad_speaker.tolist(),index = sample_df.index)\n",
    "            sample_df[['valence_listener','arousal_listener','dominance_listener']] = pd.DataFrame(sample_df.vad_listener.tolist(),index = sample_df.index)\n",
    "            sample_df = sample_df.drop(columns = ['vad_speaker','vad_listener'])                \n",
    "            sample_df['emotional_similarity'] = sample_df.apply(data_processer.get_cosine_similarity,axis = 1) \n",
    "            sample_df['mimicry'] = sample_df.apply(lambda x: 1 if x['emotional_similarity'] > 0.7 else 0, axis = 1)\n",
    "            sample_df = sample_df.drop(columns =  ['valence_speaker','arousal_speaker','dominance_speaker','valence_listener','arousal_listener','dominance_listener','emotional_similarity'])\n",
    "        sample_df['mimicry'] = sample_df['mimicry'].astype('category')\n",
    "        sample_df['mimicry'] = sample_df['mimicry'].astype('string')\n",
    "    print('done')\n",
    "    return sample_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53078ccd-bfa0-4c1c-8a7d-b9c4572d2008",
   "metadata": {},
   "source": [
    "### database setup\n",
    "\n",
    "We load the database. Next, we filter it to have only samples that start a conversation. This is done by selecting those that have an \"exchange_number\" variable of 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5739e968-0026-46a3-80cf-8d9ec1ed07d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "database = pd.read_csv(current_dir + database_dir)\n",
    "\n",
    "starting_exchange_db = database[database['exchange_number'] == 1]\n",
    "starting_exchange_db = starting_exchange_db.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de78d7e6-b49d-4268-9b9f-41f665cb382e",
   "metadata": {},
   "source": [
    "### Load our classification model\n",
    "\n",
    "In this cell, we run the empathy classification model that we have previously trained. The model selection is done through specifying the directory in which the model was saved. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ec3862b-594f-4d71-bbf2-c3fc7c672abd",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_directory = current_dir + '/Experiments/outputs/Experiment '+ str(70) + '/' + 'trained_pbc4cip.sav'\n",
    "\n",
    "pbc = pickle.load(open(model_directory, 'rb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a4fd79-91cd-47cf-bfc8-8aac6c569646",
   "metadata": {},
   "source": [
    "## Application\n",
    "\n",
    "In this subsection, we present that working parts of the demo. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93e8509-f8a2-49ba-99ba-5ae0b971e6a4",
   "metadata": {},
   "source": [
    "### Conversation starter\n",
    "\n",
    "We randomly sample the database for a conversation prompt. This is equivalent to an utterance of a first agent, to which we will provide a response. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb94567e-25c0-4522-8f1e-a68816831299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"I got approved to adopt a dog!\"\n"
     ]
    }
   ],
   "source": [
    "len_of_db = len(starting_exchange_db)\n",
    "index_of_sample = random.randint(0, len_of_db)\n",
    "\n",
    "\n",
    "sample_text = starting_exchange_db.loc[index_of_sample,'speaker_utterance']\n",
    "\n",
    "sample_text = re.sub(\"_comma_\", ',', sample_text)\n",
    "\n",
    "print(f'Prompt: \"{sample_text}\"') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "066c2edf-6f8b-439c-983f-2c4dce6b04fa",
   "metadata": {},
   "source": [
    "### Response\n",
    "\n",
    "We provide a response to the prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "963666b4-3915-4a26-b780-b3d98d972397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide your response:  I'm so glad, I love dogs\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "while(flag):\n",
    "    answer = input(\"Provide your response: \")\n",
    "    if answer.lower() == '':\n",
    "        print('No answer received, please provide a response')\n",
    "    else:\n",
    "        flag = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8de813-f386-40e2-8e56-83395a83517f",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "In this cell, the prompt-response pair is processed to have the format and features required for the classification algorithm. \n",
    "\n",
    "Subsequently, the data is passed to the classifier, and a prediction it made. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "427849ee-3c1d-4775-80b9-3a59b8e70732",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing data....\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "data = {'speaker_utterance': [sample_text], 'listener_utterance': [answer]}\n",
    "df = starting_exchange_db.iloc[[index_of_sample]]\n",
    "df = df.reset_index(drop=True)\n",
    "columns_list = starting_exchange_db.columns.to_list()\n",
    "df.loc[0, 'listener_utterance'] = str(answer)\n",
    "C = list(set(columns_list) - set(['speaker_utterance','listener_utterance','empathy','exchange_number']))\n",
    "df = df.drop(columns = C)\n",
    "df = process_answer(df,feature_vector)\n",
    "df.loc[0, 'listener_utterance']\n",
    "df = df.drop(columns = ['speaker_utterance', 'listener_utterance'])\n",
    "x_test = df.drop(columns=['empathy'])\n",
    "y_test = df.drop(columns=x_test.columns)\n",
    "y_pred = pbc.predict(x_test)\n",
    "y_pred\n",
    "\n",
    "print(f'Our classification algorithm predicts a level of {y_pred + 1} out of 3 for the perceived empathy of your response')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc98f26b-96ed-42b6-a501-e84cc15e4828",
   "metadata": {},
   "source": [
    "### pass it to the model and predict value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0c98b9fa-e056-4101-a86a-268fec4585e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                   \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
