{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02d0a22c-4c57-42ec-9fd1-acccab9a2cc7",
   "metadata": {},
   "source": [
    "# DEMO: Empathy classification using a pattern classifier\n",
    "\n",
    "In this notebook, it is possible to use a previously trained contrast-pattern classification algorithm to obtain the empathy level of a conversation between two people. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c7d243c2-35f2-4a20-a573-6142fc14b163",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import re\n",
    "#import classifier\n",
    "from PBC4cip import PBC4cip\n",
    "from PBC4cip.core.Evaluation import obtainAUCMulticlass\n",
    "from PBC4cip.core.Helpers import get_col_dist, get_idx_val\n",
    "\n",
    "#utilities for database management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm, trange\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import train_classifier as trainer\n",
    "import test_classifier as tester\n",
    "import database_processing_package as data_processer\n",
    "\n",
    "#relevant classifiers for annotating exchange feature\n",
    "from classifiers.empathetic_intent import intent_prediction as ip\n",
    "from classifiers.sentiment import sentiment_prediction as sp\n",
    "from classifiers.epitome_mechanisms import epitome_predictor as epitome\n",
    "from classifiers.nrc_vad_lexicon import lexicon_analysis as lexicon\n",
    "from classifiers.course_grained_emotion import pretrained_32emotions as em32\n",
    "from classifiers.course_grained_emotion import emotion_reductor as em_red\n",
    "\n",
    "from spellchecker import SpellChecker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44d9ab96-e4aa-47e5-b4f4-5face72f158e",
   "metadata": {},
   "source": [
    "## Loading utilities and models\n",
    "\n",
    "First, we will obtain the model, and load all utilities necessary for obtaining the features for a conversation exchange. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74aab462-ebf7-495c-ba30-168b3f718f71",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Relevant directories\n",
    "current_dir = os.getcwd() #get directory of the repository\n",
    "#Select an appropriate classification model in the Experiments folder\n",
    "model_directory = current_dir + '/Experiments/outputs/Experiment '+ str(25) + '/' + 'trained_pbc4cip.sav'\n",
    "\n",
    "\n",
    "feature2number = {'database_to_classify':0,'intent' : 1, 'sentiment' : 2, 'epitome':3, 'VAD_vectors':4, 'utterance_length':5, '32_emotion_labels':6,'20_emotion_labels':7, '8_emotion_labels':8, 'emotion_mimicry':9, 'Reduce_empathy_labels':10, 'exchange_number' : 11}\n",
    "feature_vector = [1,#database to pull from 0 = empatheticconversations (old), 1 empatheticexchanges (new)\n",
    "                  1,#intent\n",
    "                  1,#sentiment\n",
    "                  0,#epitome\n",
    "                  0,#vad lexicon\n",
    "                  1,#length\n",
    "                  0,#emotion 32\n",
    "                  0,#emotion 20\n",
    "                  0,#emotion 8\n",
    "                  0,#emotion mimicry\n",
    "                  1, #reduce empathy labels\n",
    "                  1 #exchange number\n",
    "                  ]\n",
    "\n",
    "if feature_vector[feature2number['database_to_classify']] == 1: \n",
    "    database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges.csv'\n",
    "else: \n",
    "    database_dir = '/processed_databases/EmpatheticConversationsExchangeFormat/EmpatheticConversations_ex.csv'\n",
    "\n",
    "#load intent model\n",
    "if feature_vector[feature2number['intent']] == 1: \n",
    "    empIntSubDir = './classifiers/empathetic_intent/'\n",
    "    model_intent,tokenizer_intent,device = ip.loadModelTokenizerAndDevice(empIntSubDir) #get model and parameters\n",
    "#load sentiment model\n",
    "if feature_vector[feature2number['sentiment']] == 1: \n",
    "    empIntSubDir = './classifiers/empathetic_intent/'\n",
    "    sent_model, sent_tokenzr = sp.loadSentimentModel() #get model and tokenizer\n",
    "#epitome model is loaded during inference due to the code of its classifier\n",
    "#load lexicon\n",
    "if feature_vector[feature2number['VAD_vectors']] == 1:\n",
    "    lexicon_df, wnl, stp_wrds = lexicon.setup_lexicon('classifiers/nrc_vad_lexicon/BipolarScale/NRC-VAD-Lexicon.txt')\n",
    "#load emotion classifier with 32 labels for any of the emotion labels options\n",
    "if (feature_vector[feature2number['32_emotion_labels']] == 1) or (feature_vector[feature2number['20_emotion_labels']] == 1) or (feature_vector[feature2number['8_emotion_labels']] == 1):\n",
    "    emo32_model, emo32_tokenzr = em32.load32EmotionsModel() #get model and tokenizer\n",
    "#it is necessary to get the VAD vectors for obtaining emotion mimicry\n",
    "if feature_vector[feature2number['emotion_mimicry']] == 1:\n",
    "    lexicon_df, wnl, stp_wrds = lexicon.setup_lexicon('classifiers/nrc_vad_lexicon/BipolarScale/NRC-VAD-Lexicon.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53078ccd-bfa0-4c1c-8a7d-b9c4572d2008",
   "metadata": {},
   "source": [
    "## Loading database\n",
    "\n",
    "Next we load load the database and get a random sample of a conversation starter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5739e968-0026-46a3-80cf-8d9ec1ed07d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: \"In university, for my major of social work, we all get mandatory internships where they place us in certain ones and we have no control over it. Some other students received cool internship placements, and I feel like mine doesn't compare. Kind of disappointed I didn't get something more interesting\"\n"
     ]
    }
   ],
   "source": [
    "database = pd.read_csv(current_dir + database_dir)\n",
    "\n",
    "starting_exchange_db = database[database['exchange_number'] == 1]\n",
    "starting_exchange_db = starting_exchange_db.reset_index()\n",
    "len_of_db = len(starting_exchange_db)\n",
    "index_of_sample = random.randint(0, len_of_db)\n",
    "\n",
    "sample_text = starting_exchange_db.loc[index_of_sample,'speaker_utterance']\n",
    "\n",
    "sample_text = re.sub(\"_comma_\", ',', sample_text)\n",
    "\n",
    "print(f'Prompt: \"{sample_text}\"') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "963666b4-3915-4a26-b780-b3d98d972397",
   "metadata": {},
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Provide your response:  adasdas\n"
     ]
    }
   ],
   "source": [
    "flag = True\n",
    "while(flag):\n",
    "    answer = input(\"Provide your response: \")\n",
    "    if answer.lower() == '':\n",
    "        print('No answer received, please provide a response')\n",
    "    else:\n",
    "        flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "427849ee-3c1d-4775-80b9-3a59b8e70732",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data = {'speaker_utterance': [sample_text], 'listener_utterance': [answer]}\n",
    "\n",
    "sample_df = starting_exchange_db.loc[index_of_sample, ]\n",
    "type(sample_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c1ec5a65-79b1-4b7f-8bc2-aa41accadd5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ism\n",
      "{\"h'm\", 'ism'}\n"
     ]
    }
   ],
   "source": [
    "spell = SpellChecker()\n",
    "\n",
    "\n",
    "\n",
    "# find those words that may be misspelled\n",
    "misspelled = spell.unknown(['something', 'is', \"I'm\", 'not'])\n",
    "\n",
    "for word in misspelled:\n",
    "    # Get the one `most likely` answer\n",
    "    print(spell.correction(word))\n",
    "\n",
    "    # Get a list of `likely` options\n",
    "    print(spell.candidates(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "85420eec-d3ff-4a54-bffb-f6990c09d2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aaaaaaaaaaa\n"
     ]
    }
   ],
   "source": [
    "print(\"aaaaaaaaaaa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c564b3-88e9-438f-b710-4e05235bc9ab",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
