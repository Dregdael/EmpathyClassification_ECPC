{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a6b6c6-ecfc-4923-8b2f-7c1bb9d48125",
   "metadata": {},
   "source": [
    "# DEMO for empathy classification\n",
    "\n",
    "In this demo, we classify the empathy in text exchanges. \n",
    "\n",
    "We provide the most supported pattern for the classification of the exchange. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367a65a-8f57-4dcd-8e31-f8b45938155d",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c241feda-8334-4a31-98e6-fc64620acb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from PBC4cip import PBC4cip\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import re\n",
    "\n",
    "\n",
    "\n",
    "import database_processing_package as data_processer\n",
    "import exchange_processing as exchange_processer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f28688-b0f0-42c8-b1e8-f39fe6b0d959",
   "metadata": {},
   "source": [
    "### Load main classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8dd876-8b08-402b-916c-5d1386a271a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for the model: \n",
      "s_negative s_neutral s_positive l_negative l_neutral l_positive predictions_ER valence_speaker arousal_speaker dominance_speaker valence_listener arousal_listener dominance_listener s_word_len l_word_len agreeing acknowledging encouraging consoling sympathizing suggesting questioning wishing neutral mimicry "
     ]
    }
   ],
   "source": [
    "#Relevant directories\n",
    "current_dir = os.getcwd() #get directory of the repository\n",
    "\n",
    "#Database\n",
    "database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges.csv'\n",
    "test_database_dir = '/processed_databases/EmpatheticExchanges/test.csv'\n",
    "database = pd.read_csv(current_dir + database_dir)\n",
    "test_db = pd.read_csv(current_dir + test_database_dir)\n",
    "\n",
    "#Select an appropriate classification model in the Experiments folder\n",
    "#number_of_model =90 #The number of the experiment for the model of interest\n",
    "\n",
    "number_of_model = 106 #Best performing model without exchange number (broader pattern recognition)\n",
    "model_directory = current_dir + '/Experiments/outputs/Experiment '+ str(number_of_model) + '/' + 'trained_pbc4cip.sav'\n",
    "pbc = pickle.load(open(model_directory, 'rb'))\n",
    "\n",
    "#Select features relevant for the model\n",
    "att_lst = [attribute[0] for attribute in pbc.dataset.Attributes]\n",
    "print('Features for the model: ')\n",
    "for attribute in att_lst:\n",
    "    print(attribute, end = ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8d488-f425-473a-9919-cd2878c5e726",
   "metadata": {},
   "source": [
    "### Load supplementary classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a94c89-a47c-4ed2-be22-0f8fcac352d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "flag_array, model_components = exchange_processer.load_supplementary_classifiers(att_lst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa0cf99e-4fa8-425a-a110-eec158710650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_components)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c21897c3-6718-4f34-b5f0-d4825776ec96",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "\n",
    "processed_exchange, y_pred  = exchange_processer.predict_exchange_empathy(pbc, flag_array, 1, att_lst,'I hate when my wife and son are away from me', \"I get that you're feeling bad but do not let it get to you. I'm sure you'll be extra happy once they are here\",model_components)\n",
    "recommendation = exchange_processer.get_recommentation(pbc, processed_exchange,'listener')\n",
    "judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,'I hate when my wife and son are away from me', \"I get that you're feeling bad but do not let it get to you. I'm sure you'll be extra happy once they are here\",model_components,\"listener\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "6b4012c7-8096-4640-876a-dd356e1af0bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Great chat. Though I am still curious about some things, maybe next time you could ask eachother more questions \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                          "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,'I hate when my wife and son are away from me', \"Aww that is sweet You are a good dad\",model_components,\"listener\")\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,'My little cousin  was nice and gave me a present!', \"Aww cool! was the ocasion special?\",model_components,\"listener\")\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"Does it bother you when your friends have all dates and you're single? It makes me feel inadecuate\", \"Yeah, it really sucks loneliness is no easy thing to go though\",model_components,\"listener\")\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"Does it bother you when your friends have all dates and you're single? It makes me feel inadecuate\", \"Yeah, you are \",model_components,\"listener\")\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"Does it bother you when your friends have all dates and you're single? It makes me feel inadecuate\", \"Oh yeah, it bothers me a lot too! \",model_components,\"listener\")\n",
    "\n",
    "\n",
    "\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"I was so mad earlier someone hit my car and just drove off!\", \"Fucking really? That sucks so much I would be pissed! \",model_components,\"listener\")\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"I was so mad earlier someone hit my car and just drove off!\", \"That's what you get lmao! \",model_components,\"listener\")\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"I was so mad earlier someone hit my car and just drove off!\", \"Aww man, that's not ideal Did you get the plates?\",model_components,\"listener\")\n",
    "#judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"I was so mad earlier someone hit my car and just drove off!\", \"Was it a bad accident?\",model_components,\"listener\")\n",
    "\n",
    "\n",
    "judge_exchange = exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"I was so mad earlier someone hit my car and just drove off!\", \"Was it a bad accident?\",model_components,\"listener\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9208ce61-4d17-460a-9e4e-09dd62c16f29",
   "metadata": {},
   "source": [
    "print(\"First exchange\")\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"i loved taking care of my sisters pet\", \"Huh, is that so\",model_components, 'listener')\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"i loved taking care of my sisters pet\", \"It's cool that you loved that\",model_components, 'listener')\n",
    "print(\"Second exchange\")\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"Yeah! I have loved animals since then especially dogs\", \"Dogs are very cute. Cats too\",model_components, \"listener\")\n",
    "print(\"Third exchange\")\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"Oh my gosh yes. Cats are so fluffy and cuddly\", \"They are! I love petting them\", model_components,\"listener\")\n",
    "print(\"Fourth exchange\")\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"You know i really enjoy having pets they bring a new life into an empty feeling house\", \"Yes I only have one cat. How about you?\",model_components, \"listener\")\n",
    "print(\"Fifth exchange\")\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"we have a cat, a dog, a bunny, and a betta fish!\", \"Those are many pets\", model_components, \"listener\")\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"we have a cat, a dog, a bunny, and a betta fish!\", \"Those are many pets, how do you manage?\",model_components, \"listener\")\n",
    "print(\"Sixth exchange\")\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"It is a lot of work. But their little faces are so worth it\", \"Yes they are I bet you feel proud\",model_components, \"listener\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "578112f1-1657-4bef-9ddd-a71a473ecf78",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: Respond with sympathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: My sensors say that we should encourage them about their feelings listener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: My sensors say that we should encourage them about their feelings listener\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"I was really nervous to move across country.\", \"why were you?\",model_components, 'listener')\n",
    "\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"Knew noone where we were moving and also far away from my mother_comma_ who is getting old.\", \"no one knew that you were moving?\",model_components, 'listener')\n",
    "\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"oh sorry_comma_ we knew no one where we were moving to\", \"oh_comma_ that has to be scary\",model_components, 'listener')\n",
    "\n",
    "exchange_processer.judge_exchange(pbc,flag_array,att_lst,\"Amazingly lol. But here I am.\", \"here you are, killing it\",model_components, 'listener')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56640823-d99a-4bf8-8ec4-9e016b6c95e2",
   "metadata": {},
   "source": [
    "### testing new VA vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a480f61-da2e-4813-b79a-2517ab7ec77e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i felt happy this morning because it was sunny and warm', 'That is always a great start to a day.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['absolutely_comma_ i was overjoyed.', 'How are you celebrating it?']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                 \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   valence_speaker  valence_listener  arousal_listener  arousal_listener  \\\n",
      "0           0.5324             0.574         -0.090667         -0.090667   \n",
      "1           0.8160             0.854          0.720000          0.720000   \n",
      "\n",
      "   pred_text  \n",
      "0        3.0  \n",
      "1        2.0  \n",
      "   exchange  arousal_right  valence_right  arousal_left  valence_left\n",
      "0         0       0.227728       0.041182     -0.123679     -0.008871\n",
      "1         1       0.333640       0.126210     -0.126105      0.483021\n",
      "   valence_speaker  valence_listener  arousal_listener  arousal_listener  \\\n",
      "0         0.041182         -0.008871         -0.123679         -0.123679   \n",
      "1         0.126210          0.483021         -0.126105         -0.126105   \n",
      "\n",
      "   pred_text  \n",
      "0        3.0  \n",
      "1        2.0  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                                                                                                                                                                                                                                                                                                 \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>s_negative</th>\n",
       "      <th>s_neutral</th>\n",
       "      <th>s_positive</th>\n",
       "      <th>l_negative</th>\n",
       "      <th>l_neutral</th>\n",
       "      <th>l_positive</th>\n",
       "      <th>predictions_ER</th>\n",
       "      <th>valence_speaker</th>\n",
       "      <th>arousal_speaker</th>\n",
       "      <th>dominance_speaker</th>\n",
       "      <th>...</th>\n",
       "      <th>consoling</th>\n",
       "      <th>sympathizing</th>\n",
       "      <th>suggesting</th>\n",
       "      <th>questioning</th>\n",
       "      <th>wishing</th>\n",
       "      <th>neutral</th>\n",
       "      <th>mimicry</th>\n",
       "      <th>pred_text</th>\n",
       "      <th>pred_video</th>\n",
       "      <th>empathy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.001195</td>\n",
       "      <td>0.009932</td>\n",
       "      <td>0.988873</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.010211</td>\n",
       "      <td>0.988219</td>\n",
       "      <td>0</td>\n",
       "      <td>0.041182</td>\n",
       "      <td>0.227728</td>\n",
       "      <td>0.1392</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.000047</td>\n",
       "      <td>0.000618</td>\n",
       "      <td>0.000070</td>\n",
       "      <td>1</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002673</td>\n",
       "      <td>0.017373</td>\n",
       "      <td>0.979954</td>\n",
       "      <td>0.016285</td>\n",
       "      <td>0.619967</td>\n",
       "      <td>0.363749</td>\n",
       "      <td>0</td>\n",
       "      <td>0.126210</td>\n",
       "      <td>0.333640</td>\n",
       "      <td>0.5100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>0.000186</td>\n",
       "      <td>0.999210</td>\n",
       "      <td>0.000184</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   s_negative  s_neutral  s_positive  l_negative  l_neutral  l_positive  \\\n",
       "0    0.001195   0.009932    0.988873    0.001571   0.010211    0.988219   \n",
       "1    0.002673   0.017373    0.979954    0.016285   0.619967    0.363749   \n",
       "\n",
       "  predictions_ER  valence_speaker  arousal_speaker  dominance_speaker  ...  \\\n",
       "0              0         0.041182         0.227728             0.1392  ...   \n",
       "1              0         0.126210         0.333640             0.5100  ...   \n",
       "\n",
       "   consoling  sympathizing  suggesting questioning   wishing   neutral  \\\n",
       "0   0.000376      0.000095    0.000054    0.000047  0.000618  0.000070   \n",
       "1   0.000014      0.000069    0.000186    0.999210  0.000184  0.000126   \n",
       "\n",
       "   mimicry  pred_text  pred_video  empathy  \n",
       "0        1        3.0           3        1  \n",
       "1        1        2.0           1        1  \n",
       "\n",
       "[2 rows x 28 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_exchange, y_pred  = exchange_processer.predict_exchange_empathy(pbc, flag_array, 1, att_lst,'I hate when my wife and son are away from me', \"I get that you're feeling bad but do not let it get to you. I'm sure you'll be extra happy once they are here\",model_components)\n",
    "\n",
    "#string_arr = [[\"I was really nervous to move across country\", \"why were you?\"],\n",
    "#              [\"Knew no one where we were moving_comma_ and also far away from my mother_comma_ who is getting old.\", \"no one knew that you were moving?\"],\n",
    "#              [\"oh sorry, we knew no one where we were moving to\", \"oh, that has to be scary\"],\n",
    "#              [\"Amazingly lol. But here I am.\", \"here you are, killing it\"]]\n",
    "\n",
    "string_arr = [\n",
    "              [\"i felt happy this morning because it was sunny and warm\", \"That is always a great start to a day.\"],\n",
    "              [\"absolutely_comma_ i was overjoyed.\", \"How are you celebrating it?\"]]\n",
    "              #[\"I am furious_comma_ my cell phone bill this month is 200 dollars more than last months.\", \"Wowza_comma_ did you call to complain?\"],\n",
    "              #[\"That is what I will be doing next thing tomorrow_comma_ they did not even give me a reason!\", \"Phone companies are notorious for this. I hope you are able to resolve.\"]]\n",
    "\n",
    "\n",
    "\n",
    "exchanges_df = pd.DataFrame(columns=processed_exchange.columns)\n",
    "\n",
    "\n",
    "for ex in string_arr:\n",
    "    print(ex)\n",
    "    single_exchange, y_pred  = exchange_processer.predict_exchange_empathy(pbc, flag_array, 1, att_lst, ex[0], ex[1], model_components)\n",
    "    single_exchange['pred_text'] = y_pred\n",
    "    exchanges_df = pd.concat([exchanges_df, single_exchange])\n",
    "\n",
    "exchanges_df = exchanges_df.reset_index(drop= True)\n",
    "\n",
    "#print(exchanges_df)\n",
    "print(exchanges_df[['valence_speaker', 'valence_listener', 'arousal_listener', 'arousal_listener', 'pred_text']])\n",
    "\n",
    "\n",
    "\n",
    "video_av_values = pd.read_csv(current_dir + '/exchanges_morning.csv')\n",
    "print(video_av_values)\n",
    "\n",
    "exchanges_df['valence_speaker'] = video_av_values['valence_right']\n",
    "exchanges_df['arousal_speaker'] = video_av_values['arousal_right']\n",
    "exchanges_df['valence_listener'] = video_av_values['valence_left']\n",
    "exchanges_df['arousal_listener'] = video_av_values['arousal_left']\n",
    "\n",
    "\n",
    "print(exchanges_df[['valence_speaker', 'valence_listener', 'arousal_listener', 'arousal_listener', 'pred_text']])\n",
    "\n",
    "#mimicry\n",
    "#exchanges_df['emotional_similarity'] = exchanges_df.apply(data_processer.get_cosine_similarity,axis = 1) \n",
    "#exchanges_df['mimicry'] = exchanges_df.apply(lambda x: 1 if x['emotional_similarity'] > 0.7 else 0, axis = 1)\n",
    "#exchanges_df = exchanges_df.drop(columns = ['emotional_similarity'])\n",
    "\n",
    "\n",
    "exchanges_df['pred_video'] = pbc.predict(exchanges_df)\n",
    "exchanges_df['pred_video'] = exchanges_df['pred_video'] + 1\n",
    "exchanges_df['empathy'] = 1\n",
    "exchanges_df.to_csv('exchange_predictions_morning.csv')\n",
    "exchanges_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "fe9c853c-df01-41bd-97ed-0959c5d34e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "   s_negative  s_neutral  s_positive  l_negative  l_neutral  l_positive  \\\n",
      "0    0.574606   0.387071    0.038323    0.375899   0.594197    0.029904   \n",
      "\n",
      "   predictions_ER  valence_speaker  arousal_speaker  dominance_speaker  ...  \\\n",
      "0               0         0.301333        -0.084667          -0.031333  ...   \n",
      "\n",
      "   agreeing  acknowledging  encouraging  consoling  sympathizing  suggesting  \\\n",
      "0  0.000062       0.000078     0.000021   0.000021      0.000109    0.000099   \n",
      "\n",
      "   questioning   wishing   neutral  mimicry  \n",
      "0     0.999338  0.000085  0.000187        1  \n",
      "\n",
      "[1 rows x 25 columns]\n",
      "   s_negative  s_neutral  s_positive  l_negative  l_neutral  l_positive  \\\n",
      "0    0.574606   0.387071    0.038323    0.375899   0.594197    0.029904   \n",
      "\n",
      "   predictions_ER  valence_speaker  arousal_speaker  dominance_speaker  ...  \\\n",
      "0               0        -0.061516         0.038489          -0.031333  ...   \n",
      "\n",
      "   agreeing  acknowledging  encouraging  consoling  sympathizing  suggesting  \\\n",
      "0  0.000062       0.000078     0.000021   0.000021      0.000109    0.000099   \n",
      "\n",
      "   questioning   wishing   neutral  mimicry  \n",
      "0     0.999338  0.000085  0.000187        1  \n",
      "\n",
      "[1 rows x 25 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "processed_exchange, y_pred  = exchange_processer.predict_exchange_empathy(pbc, flag_array, 1, att_lst,\"Knew no one where we were moving_comma_ and also far away from my mother_comma_ who is getting old.\", \"no one knew that you were moving?\",model_components)\n",
    "print(y_pred)\n",
    "print(processed_exchange)\n",
    "processed_exchange.loc[0,'valence_speaker'] = -0.0615155920987168\n",
    "processed_exchange.loc[0,'arousal_speaker'] = 0.0384891806771198\n",
    "processed_exchange.loc[0,'valence_listener'] = -0.0883875858710437\n",
    "processed_exchange.loc[0,'arousal_listener'] = -0.0113459913457026\n",
    "processed_exchange['emotional_similarity'] = processed_exchange.apply(data_processer.get_cosine_similarity,axis = 1) \n",
    "processed_exchange['mimicry'] = processed_exchange.apply(lambda x: 1 if x['emotional_similarity'] > 0.7 else 0, axis = 1)\n",
    "processed_exchange = processed_exchange.drop(columns = ['emotional_similarity'])\n",
    "print(processed_exchange)\n",
    "#print(processed_exchange)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6798a2f2-791a-455d-a4a2-f10a340b01e1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_exchange_empathy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_exchange, y_pred  \u001b[38;5;241m=\u001b[39m predict_exchange_empathy(pbc, flag_array, \u001b[38;5;241m1\u001b[39m, att_lst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mHow are you?\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDoing pretty good, how about yourself?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(y_pred)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(processed_exchange)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_exchange_empathy' is not defined"
     ]
    }
   ],
   "source": [
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'How are you?', \"Doing pretty good, how about yourself?\")\n",
    "print(y_pred)\n",
    "print(processed_exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3551b40e-cb48-437f-aba0-728c2b612575",
   "metadata": {},
   "outputs": [],
   "source": [
    "arguments = [pbc, flag_array, 1, att_lst, 'How are you?', \"Doing pretty good, how about yourself?\"]\n",
    "arguments.extend(model_components)\n",
    "processed_exchange, y_pred  = exchange_processer.predict_exchange_empathy_source(*arguments)\n",
    "print(y_pred)\n",
    "print(processed_exchange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06bdf55e-6c7e-4b12-abda-cc45dc23ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    bad_input_flag = True\n",
    "    while bad_input_flag:\n",
    "        utterance = input(\"Provide input: \")\n",
    "        if utterance.lower() == '':\n",
    "            print('Please provide valid input')\n",
    "        else:\n",
    "            bad_input_flag = False    \n",
    "    return utterance \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60133a3e-af0a-45e3-a95b-8c15d1ae8047",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_exchange(pbc,flag_array,att_lst,'I hate when my wife and son are away from me', \"Oh ok. \",\"listener\")\n",
    "judge_exchange(pbc,flag_array,att_lst,'I hate when my wife and son are away from me', \"I've never been in that situation but that is understandable. \",\"listener\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c4847-da01-4ea1-91df-08ca06ba8d43",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5088618-fb00-4c0b-b2f0-4d091ce756c4",
   "metadata": {},
   "source": [
    "## Examples of inference and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dde1d04-5fe6-4c4b-a439-ebca34d8c0ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'finally got my house, I do not have to deal with apartment living anymore', \"apartments are ok\",\"listener\")\n",
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'finally got my house, I do not have to deal with apartment living anymore', \"apartments are ok, you shouldn't knock them\",\"listener\")\n",
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'finally got my house, I do not have to deal with apartment living anymore', \"That's great I love living in my apartment but I'm happy for you\",\"listener\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16dbbf-eff2-4ac1-b316-892b89779d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e8ffde58-acde-4dea-8d2c-3e73e9707f3d",
   "metadata": {},
   "source": [
    "## Automatic conversation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327eb626-7772-4d41-9992-d50f1c170b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkr = [\"I cannot wait for the newest Pokemon game, it looks amazing to me!\", \"I see your point, but I still think it is fun\",'abortsequence']\n",
    "lstnr = ['pokemon is just ok',\"Oh well it's not bad. I had fun with pokemon when I was 10\", \"I relate to that, I listen to old songs from my childhood\",'abortsequence']\n",
    "\n",
    "speaker_utterances = []\n",
    "listener_utterances = []\n",
    "\n",
    "conversation_end = False\n",
    "#For a short conversation \n",
    "for i in range(2):    \n",
    "    if i>0:\n",
    "        j = i\n",
    "        while not good_speaker:\n",
    "            prompt = spkr[j]\n",
    "            print(f\"Speaker turn: {prompt}\")\n",
    "            print('Speaker_empathy')\n",
    "            good_speaker = judge_exchange(pbc, flag_array, att_lst, listener_utterances[i-1],prompt,'speaker')\n",
    "            j = j+1\n",
    "            #judgement_on_speaker = False\n",
    "            #print(f'judgement on speaker {judgement_on_speaker}')\n",
    "    else:      \n",
    "        prompt = spkr[i]\n",
    "        print(f\"Speaker turn: {prompt}\")\n",
    "        if 'abortsequence' in prompt:\n",
    "            break\n",
    "        good_speaker = False    \n",
    "        \n",
    "    \n",
    "    \n",
    "    speaker_utterances.append(prompt) #We append the successful utterance to the record\n",
    "    good_listener = False\n",
    "    #Keep listener hostage while they do not provide empathetic responses\n",
    "    j = i\n",
    "    while not good_listener:\n",
    "        answer = lstnr[j]\n",
    "        print(f\"Listener turn: {answer}\")\n",
    "        if 'abortsequence' in answer:\n",
    "            break\n",
    "        good_listener = judge_exchange(pbc, flag_array, att_lst, speaker_utterances[i], answer,'listener')\n",
    "        j = j+1\n",
    "        #print(f\"Speaker: {speaker_utterances[i]}\")\n",
    "        #print(f\"Listener: {listener_utterances[i]}\")     \n",
    "    listener_utterances.append(answer)\n",
    "\n",
    "\n",
    "print(speaker_utterances)\n",
    "print(listener_utterances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dad3c7ca-add5-4495-a3ea-3d82d9ad0142",
   "metadata": {},
   "outputs": [],
   "source": [
    "spkr = [\"I cannot wait for the newest Pokemon game, it looks amazing to me!\", \"I see your point, but I still think it is fun\",'abortsequence']\n",
    "lstnr = ['pokemon is just ok',\"Oh well it's not bad. I had fun with pokemon when I was 10\", \"Yeah it was to me, maybe I should try the new one\",'abortsequence']\n",
    "\n",
    "speaker_utterances = []\n",
    "listener_utterances = []\n",
    "\n",
    "conversation_end = False\n",
    "#For a short conversation\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "\n",
    "while not conversation_end:    \n",
    "    if j>0:\n",
    "        good_speaker = False    \n",
    "        while not good_speaker:\n",
    "            prompt = spkr[j]\n",
    "            print(f\"Speaker turn: {prompt}\")\n",
    "            print('Speaker_empathy')\n",
    "            good_speaker = judge_exchange(pbc, flag_array, att_lst, lstnr[i-1],prompt,'speaker')\n",
    "            j = j+1\n",
    "            if j + 1 >= len(spkr):\n",
    "                conversation_end = True\n",
    "            #judgement_on_speaker = False\n",
    "            #print(f'judgement on speaker {judgement_on_speaker}')\n",
    "    else:      \n",
    "        prompt = spkr[i]\n",
    "        print(f\"Speaker turn: {prompt}\")\n",
    "        if 'abortsequence' in prompt:\n",
    "            break\n",
    "        good_speaker = False    \n",
    "        if j + 1 >= len(spkr):\n",
    "            conversation_end = True\n",
    "        else:\n",
    "            j += 1        \n",
    "    speaker_utterances.append(prompt) #We append the successful utterance to the record\n",
    "    good_listener = False\n",
    "    #Keep listener hostage while they do not provide empathetic responses\n",
    "    while not good_listener:\n",
    "        answer = lstnr[i]\n",
    "        print(f\"Listener turn: {answer}\")\n",
    "        if 'abortsequence' in answer:\n",
    "            conversation_end = True\n",
    "            break\n",
    "        good_listener = judge_exchange(pbc, flag_array, att_lst, spkr[j], answer,'listener')\n",
    "        i = i+1\n",
    "        #print(f\"Speaker: {speaker_utterances[i]}\")\n",
    "        #print(f\"Listener: {listener_utterances[i]}\")     \n",
    "    listener_utterances.append(answer)\n",
    "    if i + 1 >= len(lstnr):\n",
    "        conversation_end = True\n",
    "    else:\n",
    "        i += 1\n",
    "    print(f'{i} {j}')\n",
    "        \n",
    "\n",
    "\n",
    "print(speaker_utterances)\n",
    "print(listener_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f6c87-f9cc-48d4-be62-7446f745bb74",
   "metadata": {},
   "source": [
    "## Conversation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64ffdc2-b236-4dfd-af41-441612c69684",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_utterances = []\n",
    "listener_utterances = []\n",
    "#For a short conversation \n",
    "for i in range(2):    \n",
    "    print(\"Speaker, \", end = '')\n",
    "    prompt = get_input()\n",
    "    if 'abortsequence' in prompt:\n",
    "        break\n",
    "    speaker_utterances.append(prompt) \n",
    "    good_exchange = False\n",
    "    #Keep listener hostage while they do not provide empathetic responses\n",
    "    while not good_exchange:\n",
    "        print(\"Listener,  \", end = '')\n",
    "        answer = get_input()\n",
    "        if 'abortsequence' in answer:\n",
    "            break\n",
    "        listener_utterances.append(answer)\n",
    "        print(f\"Speaker: {speaker_utterances[i]}\")\n",
    "        print(f\"Listener: {listener_utterances[i]}\")\n",
    "        good_exchange = judge_exchange(pbc, flag_array, att_lst, speaker_utterances[i], listener_utterances[i],'listener')\n",
    "    if i>0:\n",
    "        judgement_on_speaker = judge_exchange(pbc, flag_array, att_lst, listener_utterances[i-1],speaker_utterances[i],'speaker')\n",
    "        #judgement_on_speaker = False\n",
    "        print(f'judgement on speaker {judgement_on_speaker}')\n",
    "\n",
    "print(speaker_utterances)\n",
    "print(listener_utterances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5b4c602-4df8-4137-9b4f-48e2367bcaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    bad_input_flag = True\n",
    "    while bad_input_flag:\n",
    "        utterance = input(\"Provide input: \")\n",
    "        if utterance.lower() == '':\n",
    "            print('Please provide valid input')\n",
    "        else:\n",
    "            bad_input_flag = False    \n",
    "    return utterance \n",
    "\n",
    "utterance = get_input()\n",
    "\n",
    "print(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9638d006-9e16-4f10-91c4-856fa01bc3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'How are you?', \"Doing pretty good, how about yourself?\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"I'm doing ok, just had a dental implant done\", \"Oh, ouch, that must have been pretty painful\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yeah, It was. But not as bad as you would think\", \"Great to hear, and now you have a shiny new tooth!\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yes! That makes it all worth it in the end\", \"For sure, despite the bad you get something great out of it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d33065c-219e-496c-ab91-ee1e8273834a",
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_exchange(pbc, flag_array, att_lst, \"Oh, ouch, that must have been pretty painful\",  \"Yeah, It was. But not as bad as you would think\", 'listener')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbab16d-7ffc-4c51-92d6-1fc4adcedae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidates = []\n",
    "for i in database['prompt']:\n",
    "    if(len(database[database['prompt'] == i]) >= 4 ):\n",
    "        #print(database[database['prompt'] == i])\n",
    "        candidates.append(i)\n",
    "set(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11f6a7ac-2798-4f10-af85-6cb4cb97547b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend pretty much and I have a hard time with loneliness on the weekends especially.', \"I am sorry. Maybe not focus as friday-sunday as the weekend_comma_ but as any other day. And do things you would normally do on other days.\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n",
    "\n",
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend and I have a hard time with loneliness on the weekends especially.', \"I love the weekends actually\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n",
    "\n",
    "\n",
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend and I have a hard time with loneliness on the weekends especially.', \"Sorry to hear you are feeling lonely. But don't worry I am your friend\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n",
    "\n",
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend pretty much and I have a hard time with loneliness on the weekends especially.', \"Sorry to hear that, maybe you should go join a club to meet new people\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86a73bf1-fff0-40cc-97ca-839dfc85513a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"First exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"i loved taking care of my sisters pet\", \"Huh, is that so\", 'listener')\n",
    "judge_exchange(pbc,flag_array,att_lst,\"i loved taking care of my sisters pet\", \"It's cool that you loved that\", 'listener')\n",
    "print(\"Second exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"Yeah! I have loved animals since then especially dogs\", \"Dogs are very cute. Cats too\", \"listener\")\n",
    "print(\"Third exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"Oh my gosh yes. Cats are so fluffy and cuddly\", \"They are! I love petting them\", \"listener\")\n",
    "print(\"Fourth exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"You know i really enjoy having pets they bring a new life into an empty feeling house\", \"Yes I only have one cat. How about you?\", \"listener\")\n",
    "print(\"Fifth exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"we have a cat, a dog, a bunny, and a betta fish!\", \"Those are many pets\", \"listener\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"we have a cat, a dog, a bunny, and a betta fish!\", \"Those are many pets, how do you manage?\", \"listener\")\n",
    "print(\"Six exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"It is a lot of work. But their little faces are so worth it\", \"Yes they are I bet you feel proud\", \"listener\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e71b635-d07d-414b-8fe2-d2f0d56a011b",
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'At the time there was a friend that told me that i could not jump over him_comma_ then i jumped over him.', \"Neat\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"I'm doing ok, just had a dental implant done\", \"Oh, ouch, that must have been pretty painful\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yeah, It was. But not as bad as you would think\", \"Great to hear, and now you have a shiny new tooth!\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yes! That makes it all worth it in the end\", \"For sure, despite the bad you get something great out of it\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aedae12-ac58-4649-8df3-c2161950c2c9",
   "metadata": {},
   "source": [
    "# Miscellaneous zone\n",
    "\n",
    "Where we do all sorts of experimentation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c868fd",
   "metadata": {},
   "source": [
    "### Checking pattern list that covers an exchange (values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7856afa1-792f-4613-b316-1079451b71fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'s_negative': [0.9398489], 's_neutral': [0.057078857], 's_positive': [0.0030721908], 'l_negative': [0.33885983], 'l_neutral': [0.64117646], 'l_positive': [0.019963712], 'predictions_ER': [0], 'valence_speaker': [0], 'arousal_speaker': [2], 'dominance_speaker': [-0.708], 'valence_listener': [0.656], 'arousal_listener': [-0.63], 'dominance_listener': [-0.98], 's_word_len': [0.55], 'l_word_len': [-0.51], 'agreeing': [7], 'acknowledging': [5], 'encouraging': [6.73560498398729e-05], 'consoling': [5.48729512956925e-05], 'sympathizing': [3.37222991220187e-05], 'suggesting': [1.91891886061057e-05], 'questioning': [0.000120048694953], 'wishing': [0.0005292572896], 'neutral': [0.998958706855774], 'mimicry': [0.000112920177344]}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "147"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emerging_patterns = pbc.EmergingPatterns\n",
    "emerging_patterns[0].Items[0].Value\n",
    "dummy_dic = {}\n",
    "att_lst = pbc.dataset.Attributes\n",
    "values = [0.9398489, 0.057078857, 0.0030721908, 0.33885983, 0.64117646, \n",
    "    0.019963712, 0, 0, 2, -0.708, 0.656, -0.63, -0.98, 0.55, -0.51, \n",
    "    7, 5, 6.73560498398729E-05, 5.48729512956925E-05, 3.37222991220187E-05, \n",
    "    1.91891886061057E-05, 0.000120048694953, 0.0005292572896, 0.998958706855774, \n",
    "    0.000112920177344, 0.000103849401057, 1]\n",
    "\n",
    "for i in range(len(att_lst)):\n",
    "    new_data = {str(att_lst[i][0]): [values[i]]}\n",
    "    dummy_dic.update(new_data)\n",
    "\n",
    "\n",
    "print(dummy_dic)\n",
    "\n",
    "exchange_df = pd.DataFrame.from_dict(dummy_dic)\n",
    "\n",
    "pbc.predict(exchange_df)\n",
    "\n",
    "\n",
    "pattern_list = [] #patterns that cover the exchange\n",
    "\n",
    "for instance in exchange_df.to_numpy(): \n",
    "    for pattern in emerging_patterns:\n",
    "        if pattern.IsMatch(instance):\n",
    "            pattern_list.append(pattern)   \n",
    "len(pattern_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ef5bba9-50e6-477a-ae5d-2d87e23ed6ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predict_exchange_empathy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m processed_exchange, y_pred  \u001b[38;5;241m=\u001b[39m predict_exchange_empathy(pbc, flag_array, \u001b[38;5;241m1\u001b[39m, att_lst, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAt the time there was a friend that told me that i could not jump over him_comma_ then i jumped over him.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeato burrito\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'predict_exchange_empathy' is not defined"
     ]
    }
   ],
   "source": [
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'At the time there was a friend that told me that i could not jump over him_comma_ then i jumped over him.', \"Neato burrito\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d9a269fd-f3c1-4893-9c0e-a0911fe6c49e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'judge_exchange' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m judge_exchange(pbc,flag_array,att_lst,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAt the time there was a friend that told me that i could not jump over him_comma_ then i jumped over him.\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNeato burrito\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlistener\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'judge_exchange' is not defined"
     ]
    }
   ],
   "source": [
    "judge_exchange(pbc,flag_array,att_lst,'At the time there was a friend that told me that i could not jump over him_comma_ then i jumped over him.', \"Neato burrito\", 'listener')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831ef456-f3cf-4a11-af11-12c000b54f2c",
   "metadata": {},
   "source": [
    "### load predictions on dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9817586a-500a-4d94-8b06-4a1c778ab3ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>conv_id</th>\n",
       "      <th>context</th>\n",
       "      <th>prompt</th>\n",
       "      <th>speaker_utterance</th>\n",
       "      <th>listener_utterance</th>\n",
       "      <th>exchange_number</th>\n",
       "      <th>s_word_len</th>\n",
       "      <th>l_word_len</th>\n",
       "      <th>empathy</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hit:10889_conv:21779</td>\n",
       "      <td>jealous</td>\n",
       "      <td>I saw my neighbor bought the car I have always...</td>\n",
       "      <td>I know_comma_ it would look perfect in front o...</td>\n",
       "      <td>Time goes by so fast. You will see.</td>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hit:1916_conv:3833</td>\n",
       "      <td>hopeful</td>\n",
       "      <td>when you expect more you have been disapponted...</td>\n",
       "      <td>yeah good. whats your name?</td>\n",
       "      <td>I am not sure I feel comfortable telling you a...</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>hit:7038_conv:14076</td>\n",
       "      <td>impressed</td>\n",
       "      <td>My coworker did this presentation at work that...</td>\n",
       "      <td>I was really proud of my coworker and their pr...</td>\n",
       "      <td>That is nice. It is good to be supportive</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hit:10237_conv:20475</td>\n",
       "      <td>devastated</td>\n",
       "      <td>One time my dog got run over by a car. He had ...</td>\n",
       "      <td>Yeah. He did not survive. I really miss him</td>\n",
       "      <td>Hope everything gets better soon</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hit:5988_conv:11976</td>\n",
       "      <td>prepared</td>\n",
       "      <td>I have been working all week on my project. To...</td>\n",
       "      <td>Hi_comma_ I have a big business presentation t...</td>\n",
       "      <td>Are you fully prepared for it?</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3298</th>\n",
       "      <td>hit:9741_conv:19482</td>\n",
       "      <td>confident</td>\n",
       "      <td>I had to give a speech in front of a few of my...</td>\n",
       "      <td>I absolutely hate public speaking. I did alrig...</td>\n",
       "      <td>I bet! Well it over now and I am sure you did ...</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3299</th>\n",
       "      <td>hit:3981_conv:7962</td>\n",
       "      <td>jealous</td>\n",
       "      <td>My friend bought a new car.</td>\n",
       "      <td>An old beat up car that I need to replace but ...</td>\n",
       "      <td>I drive a gianormous conversion van</td>\n",
       "      <td>2</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3300</th>\n",
       "      <td>hit:2853_conv:5707</td>\n",
       "      <td>anxious</td>\n",
       "      <td>I was nervous when I had to go to jury duty. I...</td>\n",
       "      <td>No_comma_ I had no idea what to expect</td>\n",
       "      <td>I have never served on jury duty either. The c...</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3301</th>\n",
       "      <td>hit:8397_conv:16795</td>\n",
       "      <td>terrified</td>\n",
       "      <td>Running up the stairs in the dark when I was a...</td>\n",
       "      <td>Yeah_comma_ so I would book it up the stairs a...</td>\n",
       "      <td>I am sure I would too. Just be careful</td>\n",
       "      <td>2</td>\n",
       "      <td>13</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3302</th>\n",
       "      <td>hit:4484_conv:8169</td>\n",
       "      <td>caring</td>\n",
       "      <td>My friend has had the flu_comma_ and I have be...</td>\n",
       "      <td>My friend has had the flu_comma_ and I have be...</td>\n",
       "      <td>That is sweet of you_comma_ the flu is a prett...</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3303 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   conv_id     context  \\\n",
       "0     hit:10889_conv:21779     jealous   \n",
       "1       hit:1916_conv:3833     hopeful   \n",
       "2      hit:7038_conv:14076   impressed   \n",
       "3     hit:10237_conv:20475  devastated   \n",
       "4      hit:5988_conv:11976    prepared   \n",
       "...                    ...         ...   \n",
       "3298   hit:9741_conv:19482   confident   \n",
       "3299    hit:3981_conv:7962     jealous   \n",
       "3300    hit:2853_conv:5707     anxious   \n",
       "3301   hit:8397_conv:16795   terrified   \n",
       "3302    hit:4484_conv:8169      caring   \n",
       "\n",
       "                                                 prompt  \\\n",
       "0     I saw my neighbor bought the car I have always...   \n",
       "1     when you expect more you have been disapponted...   \n",
       "2     My coworker did this presentation at work that...   \n",
       "3     One time my dog got run over by a car. He had ...   \n",
       "4     I have been working all week on my project. To...   \n",
       "...                                                 ...   \n",
       "3298  I had to give a speech in front of a few of my...   \n",
       "3299                        My friend bought a new car.   \n",
       "3300  I was nervous when I had to go to jury duty. I...   \n",
       "3301  Running up the stairs in the dark when I was a...   \n",
       "3302  My friend has had the flu_comma_ and I have be...   \n",
       "\n",
       "                                      speaker_utterance  \\\n",
       "0     I know_comma_ it would look perfect in front o...   \n",
       "1                           yeah good. whats your name?   \n",
       "2     I was really proud of my coworker and their pr...   \n",
       "3           Yeah. He did not survive. I really miss him   \n",
       "4     Hi_comma_ I have a big business presentation t...   \n",
       "...                                                 ...   \n",
       "3298  I absolutely hate public speaking. I did alrig...   \n",
       "3299  An old beat up car that I need to replace but ...   \n",
       "3300             No_comma_ I had no idea what to expect   \n",
       "3301  Yeah_comma_ so I would book it up the stairs a...   \n",
       "3302  My friend has had the flu_comma_ and I have be...   \n",
       "\n",
       "                                     listener_utterance  exchange_number  \\\n",
       "0                   Time goes by so fast. You will see.                3   \n",
       "1     I am not sure I feel comfortable telling you a...                2   \n",
       "2             That is nice. It is good to be supportive                1   \n",
       "3                      Hope everything gets better soon                2   \n",
       "4                        Are you fully prepared for it?                1   \n",
       "...                                                 ...              ...   \n",
       "3298  I bet! Well it over now and I am sure you did ...                2   \n",
       "3299                I drive a gianormous conversion van                2   \n",
       "3300  I have never served on jury duty either. The c...                2   \n",
       "3301             I am sure I would too. Just be careful                2   \n",
       "3302  That is sweet of you_comma_ the flu is a prett...                1   \n",
       "\n",
       "      s_word_len  l_word_len  empathy  pred  \n",
       "0             33           8        3     1  \n",
       "1              5          13        1     2  \n",
       "2             13           9        3     3  \n",
       "3              9           5        1     2  \n",
       "4              8           6        3     1  \n",
       "...          ...         ...      ...   ...  \n",
       "3298          15          13        3     3  \n",
       "3299          14           6        1     1  \n",
       "3300           8          25        1     3  \n",
       "3301          13           9        2     2  \n",
       "3302          19          21        2     3  \n",
       "\n",
       "[3303 rows x 10 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pred_pbc = pd.read_csv(current_dir + '/best_predictions.txt', header = None)\n",
    "pred_pbc = pred_pbc.rename(columns = {0:'pred'})\n",
    "pred_pbc['pred'] = pred_pbc['pred'].apply(lambda x: x + 1)\n",
    "pred_pbc\n",
    "\n",
    "database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges.csv'\n",
    "\n",
    "database = pd.read_csv(current_dir + database_dir)\n",
    "X = database.drop(columns=['empathy'])\n",
    "y = database['empathy']\n",
    "\n",
    "test_db = pd.read_csv(current_dir + test_database_dir)\n",
    "test_db\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,stratify=y)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_df = test_df.reset_index(drop = True)\n",
    "test_df['pred'] = pred_pbc['pred']\n",
    "test_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf315cb-22a6-48c0-b723-3171e5813227",
   "metadata": {},
   "source": [
    "## measuring performance metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c0834c13-10ac-41e9-aeda-f05b9b9de73e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       0\n",
      "1       1\n",
      "2       1\n",
      "3       1\n",
      "4       0\n",
      "       ..\n",
      "3298    1\n",
      "3299    0\n",
      "3300    1\n",
      "3301    1\n",
      "3302    1\n",
      "Name: pred, Length: 3303, dtype: int64\n",
      "      empathy\n",
      "0           2\n",
      "1           1\n",
      "2           2\n",
      "3           1\n",
      "4           2\n",
      "...       ...\n",
      "3298        2\n",
      "3299        1\n",
      "3300        1\n",
      "3301        2\n",
      "3302        2\n",
      "\n",
      "[3303 rows x 1 columns]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7025794952465386"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import CEM as cem\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "features = test_df.columns\n",
    "features2keep = ['conv_id', 'context', 'prompt', 'speaker_utterance','listener_utterance','valence_listener','arousal_listener','empathy']\n",
    "\n",
    "features2delete = list(set(features) - set(features2keep))\n",
    "\n",
    "test_df = test_df.drop(columns = features2delete)\n",
    "\n",
    "\n",
    "test_df['pred'] = pred_pbc['pred']\n",
    "\n",
    "#x_test = test_df.drop(columns=['empathy'])\n",
    "#y_test = test_df.copy()\n",
    "#y_test = y_test.drop(columns=x_test.columns)\n",
    "\n",
    "\n",
    "#ClosenessEvaluationMeasure = cem.get_cem(test_df['pred'].apply(lambda x: x - 1),y_test)\n",
    "\n",
    "\n",
    "\n",
    "test_df['empathy_red'] = test_df.apply(lambda x: 2 if (x['empathy'] == 3 or x['empathy'] == 2)  else 1, axis = 1)\n",
    "test_df['pred_red'] = test_df.apply(lambda x: 1 if (x['pred'] == 3 or x['pred'] == 2)  else 0, axis = 1)\n",
    "test_df_2 = test_df.drop(columns=['empathy'])\n",
    "test_df_2 = test_df_2.drop(columns=['pred'])\n",
    "\n",
    "\n",
    "test_df_2 = test_df_2.rename(columns={\"empathy_red\": \"empathy\"})\n",
    "test_df_2 = test_df_2.rename(columns={\"pred_red\": \"pred\"})\n",
    "feature_columns = test_df_2.drop(columns=['empathy']).columns\n",
    "#print(test_df_2.head())\n",
    "#correct_pred_only = test_df[test_df['empathy'] ==  test_df['pred']]\n",
    "#correct_pred_only_low = correct_pred_only[correct_pred_only['empathy'] ==  1]\n",
    "\n",
    "#no_valence = test_df[test_df['valence_listener'] == 0]\n",
    "\n",
    "#no_valence = test_df[test_df['valence_listener'] > -0.1]\n",
    "#no_valence = no_valence[no_valence['valence_listener'] < 0.1]\n",
    "#no_valence = no_valence[no_valence['empathy'] != no_valence['pred']]\n",
    "\n",
    "\n",
    "#no_valence.to_csv('no_valence_wrong_label_examples.csv')\n",
    "#correct_pred_only.to_csv('correctly_predicted_exchanges.csv')\n",
    "#correct_pred_only_low.to_csv('correctly_predicted_exchanges_low.csv')\n",
    "\n",
    "#correct_pred_only_low['context'].describe()\n",
    "\n",
    "acc = accuracy_score(test_df['empathy_red'], test_df['pred_red'])\n",
    "y_pred = test_df_2['pred']\n",
    "print(y_pred)\n",
    "y_true = test_df_2.drop(columns = feature_columns)\n",
    "print(y_true)\n",
    "ClosenessEvaluationMeasure = cem.get_cem(y_pred,y_true)\n",
    "test_df\n",
    "\n",
    "test_df_2\n",
    "ClosenessEvaluationMeasure\n",
    "ClosenessEvaluationMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79c7559-b3cb-4e70-86e2-f6a15e565813",
   "metadata": {},
   "source": [
    "### get full conversations on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "01c785fc-a6ad-40e3-8728-1ae08c45668f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2931\n",
      "3303\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "362"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pred_pbc = pd.read_csv(current_dir + '/best_predictions.txt', header = None)\n",
    "pred_pbc = pred_pbc.rename(columns = {0:'pred'})\n",
    "pred_pbc['pred'] = pred_pbc['pred'].apply(lambda x: x + 1)\n",
    "pred_pbc\n",
    "\n",
    "database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges.csv'\n",
    "\n",
    "database = pd.read_csv(current_dir + database_dir)\n",
    "X = database.drop(columns=['empathy'])\n",
    "y = database['empathy']\n",
    "\n",
    "test_db = pd.read_csv(current_dir + test_database_dir)\n",
    "test_db\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42,stratify=y)\n",
    "train_df = pd.concat([X_train, y_train], axis=1)\n",
    "test_df = pd.concat([X_test, y_test], axis=1)\n",
    "test_df = test_df.reset_index(drop = True)\n",
    "test_df['pred'] = pred_pbc['pred']\n",
    "print(len(test_df['conv_id'].unique()))\n",
    "print(len(test_df['conv_id']))\n",
    "\n",
    "\n",
    "ids = test_df[\"conv_id\"]\n",
    "duplicated_convos = test_df[ids.isin(ids[ids.duplicated()])].sort_values(\"conv_id\")\n",
    "\n",
    "duplicated_convos\n",
    "\n",
    "v = duplicated_convos.conv_id.value_counts()\n",
    "duplicated_convos[duplicated_convos.conv_id.isin(v.index[v.gt(2)])]\n",
    "duplicated_convos\n",
    "duplicated_convos.to_csv('/useful_database_subsets/convos_in_test_set.csv')\n",
    "\n",
    "len(duplicated_convos['conv_id'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df41676f-48cc-4476-9220-19b042882ef6",
   "metadata": {},
   "source": [
    "### get emotionally balanced contexts from database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7ab3253-3f6d-4e5a-99b1-37286705f359",
   "metadata": {},
   "outputs": [],
   "source": [
    "from classifiers.course_grained_emotion import emotion_reductor as em_red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "30e65811-3422-4dfd-9159-846d20b08504",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the indexes of the conversations already sampled\n",
    "def get_index_list(approved_df,dataframe_list):\n",
    "  index_list = []\n",
    "  for convo in approved_df['prompt']:\n",
    "    #print(convo)\n",
    "    for  i in range(len(dataframe_list)):\n",
    "      if dataframe_list[i].loc[dataframe_list[i]['prompt'] == convo].empty == False:\n",
    "        index_list.append([i,dataframe_list[i].loc[dataframe_list[i]['prompt'] == convo].index])\n",
    "            #index_list.append([frame.index,frame.loc[frame['conv_id'] == convo].index])\n",
    "  return index_list\n",
    "\n",
    "\n",
    "#Function that deletes the conversations already sampled from the database\n",
    "def remove_accepted_convos(index_list, base_df):\n",
    "  for index in index_list:\n",
    "    base_df = base_df.drop([index[1][0]])\n",
    "  return base_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5610d425-f7b8-45e0-9f3f-4bd010524344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7996\n",
      "7996\n",
      "7899\n"
     ]
    }
   ],
   "source": [
    "database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges.csv'\n",
    "\n",
    "database = pd.read_csv(current_dir + database_dir)\n",
    "database\n",
    "starting_exchange_db = database[database['exchange_number'] == 1]\n",
    "\n",
    "\n",
    "print(len(database['conv_id'].unique()))\n",
    "print(len(starting_exchange_db))\n",
    "\n",
    "\n",
    "print(len(database['prompt'].unique()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a94c9353-a10a-49f4-ad61-69429142ba13",
   "metadata": {},
   "outputs": [],
   "source": [
    "red_emo_prompt_df = em_red.reduce_emotion_labels_to_8('context',starting_exchange_db)\n",
    "red_emo_prompt_df\n",
    "print(len(red_emo_prompt_df['context'].unique()))\n",
    "\n",
    "red_emo_prompt_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "0af87598-0d5b-4b01-b0d4-e0f78dc4801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joy_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'joy']\n",
    "anger_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'anger']\n",
    "disgust_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'disgust']\n",
    "fear_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'fear']\n",
    "trust_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'trust']\n",
    "surprise_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'surprise']\n",
    "sadness_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'sadness']\n",
    "anticipation_df = red_emo_prompt_df[red_emo_prompt_df['context']== 'anticipation']\n",
    "\n",
    "emo_df_lst = [joy_df,anger_df,disgust_df,fear_df,trust_df,surprise_df,sadness_df,anticipation_df]\n",
    "\n",
    "def get_sampled_dataframe(df_lst, extra_emotion):\n",
    "    emo_to_num = {'joy': 0, 'anger': 1, 'disgust': 2, 'fear': 3,'trust': 4,'surprise': 5,'sadness': 6,'anticipation': 7}\n",
    "    extra_index = emo_to_num[extra_emotion]\n",
    "    accepted_flag = False\n",
    "    dataframe_samples = []\n",
    "    for df in df_lst:\n",
    "        dataframe_samples.append(df.sample(n=1))\n",
    "    dataframe_samples.append(df_lst[extra_index].sample(n=1))\n",
    "    #Join samples in single dataframe\n",
    "    prepared_dataframe = dataframe_samples[0]\n",
    "    for i in range(1,len(dataframe_samples)):\n",
    "        prepared_dataframe = pd.concat([prepared_dataframe, dataframe_samples[i]])\n",
    "    prepared_dataframe.reset_index(drop=True, inplace=True)\n",
    "    prepared_dataframe['context'].describe()\n",
    "    return prepared_dataframe\n",
    "\n",
    "sampled_dataframe = get_sampled_dataframe(emo_df_lst,'fear')\n",
    "speaker_prompts = sampled_dataframe.drop(columns = set(red_emo_prompt_df.columns) - set(['prompt', 'context']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "7dd7d04f-09fd-4796-8191-9727f7d0953c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "context: joy, prompt: I remember when I was younger waiting Christmas Day to unwrap presents.  There were a lot of things I wanted that year.\n",
      "\n",
      "context: anger, prompt: My Cd player keeps skipping nothing can stop it.\n",
      "\n",
      "context: disgust, prompt: Yesterday I saw a mother beating up her kid. I couldn't believe it!\n",
      "\n",
      "context: fear, prompt: When I was a child I was in a destructive tornado. \n",
      "\n",
      "context: trust, prompt: I am happy with what I have in life.\n",
      "\n",
      "context: surprise, prompt: There is a new restaurant in my neighborhood and it is quite good. We don't have good restaurants.\n",
      "\n",
      "context: sadness, prompt: My sister is always the sibling that my parents talk about. Sometimes I wonder if they even notice me.\n",
      "\n",
      "context: anticipation, prompt: Once I realized that I needed at least a 31 on my ACT in order to get a nice little scholarship for college. I studied my heart out to improve my 29 and I felt super confident that I'd get the 31. Instead I actually got a 33!\n",
      "\n",
      "context: fear, prompt: Going to the store today was a bit hard. I do not like big stores or being around people sometimes but I have too.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range(len(speaker_prompts['prompt'])):\n",
    "    print(f\"context: {speaker_prompts.loc[i,'context']}, prompt: {speaker_prompts.loc[i,'prompt']}\")\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "4d5aab53-6439-44f9-8c53-7ce40df152a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'sadness'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/indexes/base.py:3791\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3790\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3791\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(casted_key)\n\u001b[1;32m   3792\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:152\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:181\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7080\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7088\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sadness'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[317], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m disgust_df\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindex\n\u001b[0;32m----> 2\u001b[0m disgust_df\u001b[38;5;241m.\u001b[39mloc[disgust_df\u001b[38;5;241m.\u001b[39msample(n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mindex[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msadness\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/indexing.py:1146\u001b[0m, in \u001b[0;36m_LocationIndexer.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1144\u001b[0m     key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(com\u001b[38;5;241m.\u001b[39mapply_if_callable(x, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m key)\n\u001b[1;32m   1145\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_scalar_access(key):\n\u001b[0;32m-> 1146\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_get_value(\u001b[38;5;241m*\u001b[39mkey, takeable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_takeable)\n\u001b[1;32m   1147\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_tuple(key)\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;66;03m# we by definition only have the 0th axis\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/frame.py:4005\u001b[0m, in \u001b[0;36mDataFrame._get_value\u001b[0;34m(self, index, col, takeable)\u001b[0m\n\u001b[1;32m   4002\u001b[0m     series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(col, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4003\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m series\u001b[38;5;241m.\u001b[39m_values[index]\n\u001b[0;32m-> 4005\u001b[0m series \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(col)\n\u001b[1;32m   4006\u001b[0m engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39m_engine\n\u001b[1;32m   4008\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, MultiIndex):\n\u001b[1;32m   4009\u001b[0m     \u001b[38;5;66;03m# CategoricalIndex: Trying to use the engine fastpath may give incorrect\u001b[39;00m\n\u001b[1;32m   4010\u001b[0m     \u001b[38;5;66;03m#  results if our categories are integers that dont match our codes\u001b[39;00m\n\u001b[1;32m   4011\u001b[0m     \u001b[38;5;66;03m# IntervalIndex: IntervalTree has no get_loc\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/frame.py:4414\u001b[0m, in \u001b[0;36mDataFrame._get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   4409\u001b[0m res \u001b[38;5;241m=\u001b[39m cache\u001b[38;5;241m.\u001b[39mget(item)\n\u001b[1;32m   4410\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   4411\u001b[0m     \u001b[38;5;66;03m# All places that call _get_item_cache have unique columns,\u001b[39;00m\n\u001b[1;32m   4412\u001b[0m     \u001b[38;5;66;03m#  pending resolution of GH#33047\u001b[39;00m\n\u001b[0;32m-> 4414\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mget_loc(item)\n\u001b[1;32m   4415\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ixs(loc, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m   4417\u001b[0m     cache[item] \u001b[38;5;241m=\u001b[39m res\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/indexes/base.py:3798\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3793\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3794\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3795\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3796\u001b[0m     ):\n\u001b[1;32m   3797\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3798\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3799\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3800\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3801\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3802\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3803\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'sadness'"
     ]
    }
   ],
   "source": [
    "sadness_df.sample(n=1).index\n",
    "sadness_df.loc[sadness_df.sample(n=1).index[0], 'prompt']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "5a07c68f-e054-4584-97be-d55892c16838",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_prompts.to_csv('/useful_database_subsets/prompts_20.csv', index=None)\n",
    "idxlst = get_index_list(speaker_prompts, emo_df_lst)\n",
    "red_emo_prompt_df = remove_accepted_convos(idxlst,red_emo_prompt_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "7cb63d33-6984-43b0-a761-86992b074bee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, Index([15879], dtype='int64')], [1, Index([6512], dtype='int64')], [2, Index([5743], dtype='int64')], [3, Index([11351], dtype='int64')], [4, Index([575, 9767], dtype='int64')], [5, Index([3812], dtype='int64')], [6, Index([2567], dtype='int64')], [7, Index([10674], dtype='int64')], [0, Index([8297], dtype='int64')], [0, Index([5853], dtype='int64')], [1, Index([13516], dtype='int64')], [2, Index([5399], dtype='int64')], [3, Index([7434], dtype='int64')], [4, Index([13992], dtype='int64')], [5, Index([15122], dtype='int64')], [6, Index([5228], dtype='int64')], [7, Index([1004], dtype='int64')], [0, Index([15032], dtype='int64')], [0, Index([7275], dtype='int64')], [1, Index([11825], dtype='int64')], [2, Index([7628], dtype='int64')], [3, Index([3736], dtype='int64')], [4, Index([4592], dtype='int64')], [5, Index([1058], dtype='int64')], [6, Index([13485], dtype='int64')], [7, Index([2689], dtype='int64')], [0, Index([4413], dtype='int64')], [0, Index([14087], dtype='int64')], [1, Index([12235], dtype='int64')], [2, Index([1460], dtype='int64')], [3, Index([1508], dtype='int64')], [4, Index([6150], dtype='int64')], [5, Index([7295], dtype='int64')], [6, Index([15865], dtype='int64')], [7, Index([11005], dtype='int64')], [1, Index([956], dtype='int64')], [0, Index([9501], dtype='int64')], [1, Index([13623], dtype='int64')], [2, Index([5055], dtype='int64')], [3, Index([10024], dtype='int64')], [4, Index([3579], dtype='int64')], [5, Index([1127], dtype='int64')], [6, Index([16259], dtype='int64')], [7, Index([8504], dtype='int64')], [2, Index([15895], dtype='int64')], [0, Index([10052], dtype='int64')], [1, Index([15217], dtype='int64')], [2, Index([11384], dtype='int64')], [3, Index([12611], dtype='int64')], [4, Index([6190], dtype='int64')], [5, Index([8436], dtype='int64')], [6, Index([7875], dtype='int64')], [7, Index([11143], dtype='int64')], [3, Index([15924], dtype='int64')], [0, Index([15589], dtype='int64')], [1, Index([7255], dtype='int64')], [2, Index([13627], dtype='int64')], [3, Index([915, 9735], dtype='int64')], [4, Index([11850], dtype='int64')], [5, Index([13379], dtype='int64')], [6, Index([1937], dtype='int64')], [7, Index([437], dtype='int64')], [4, Index([16493], dtype='int64')], [0, Index([9161], dtype='int64')], [1, Index([9406], dtype='int64')], [2, Index([15353], dtype='int64')], [3, Index([9838], dtype='int64')], [4, Index([8054], dtype='int64')], [5, Index([5359, 9181], dtype='int64')], [6, Index([2048], dtype='int64')], [7, Index([13049], dtype='int64')], [5, Index([14901], dtype='int64')], [0, Index([2540], dtype='int64')], [1, Index([11878], dtype='int64')], [2, Index([15486], dtype='int64')], [3, Index([8613], dtype='int64')], [4, Index([12407], dtype='int64')], [5, Index([12278], dtype='int64')], [6, Index([14565], dtype='int64')], [7, Index([3319], dtype='int64')], [6, Index([12925], dtype='int64')], [0, Index([15413], dtype='int64')], [1, Index([11476], dtype='int64')], [2, Index([16309], dtype='int64')], [3, Index([16187], dtype='int64')], [4, Index([9455], dtype='int64')], [5, Index([3460], dtype='int64')], [6, Index([14033], dtype='int64')], [7, Index([9785], dtype='int64')], [0, Index([2107], dtype='int64')], [1, Index([9213], dtype='int64')], [2, Index([5047], dtype='int64')], [3, Index([3364], dtype='int64')], [4, Index([14805], dtype='int64')], [5, Index([1983], dtype='int64')], [6, Index([5083], dtype='int64')], [7, Index([6014], dtype='int64')], [1, Index([9216], dtype='int64')], [0, Index([2915], dtype='int64')], [1, Index([566], dtype='int64')], [2, Index([12542], dtype='int64')], [3, Index([5019], dtype='int64')], [4, Index([1542], dtype='int64')], [5, Index([6270], dtype='int64')], [6, Index([6212], dtype='int64')], [7, Index([6719], dtype='int64')], [2, Index([15856], dtype='int64')], [0, Index([6216], dtype='int64')], [1, Index([1247], dtype='int64')], [2, Index([3228], dtype='int64')], [3, Index([3687], dtype='int64')], [4, Index([1351], dtype='int64')], [5, Index([13929], dtype='int64')], [6, Index([581], dtype='int64')], [7, Index([3396], dtype='int64')], [3, Index([13675], dtype='int64')]]\n",
      "117\n",
      "7880\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'[15879] not found in axis'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[242], line 16\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m#remove_accepted_convos()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(red_emo_prompt_df))\n\u001b[0;32m---> 16\u001b[0m red_emo_prompt_df \u001b[38;5;241m=\u001b[39m remove_accepted_convos(idxlst,red_emo_prompt_df)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(red_emo_prompt_df))\n",
      "Cell \u001b[0;32mIn[233], line 16\u001b[0m, in \u001b[0;36mremove_accepted_convos\u001b[0;34m(index_list, base_df)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mremove_accepted_convos\u001b[39m(index_list, base_df):\n\u001b[1;32m     15\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m index \u001b[38;5;129;01min\u001b[39;00m index_list:\n\u001b[0;32m---> 16\u001b[0m     base_df \u001b[38;5;241m=\u001b[39m base_df\u001b[38;5;241m.\u001b[39mdrop([index[\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m0\u001b[39m]])\n\u001b[1;32m     17\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m base_df\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/frame.py:5344\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   5196\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   5197\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5198\u001b[0m     labels: IndexLabel \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5205\u001b[0m     errors: IgnoreRaise \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   5206\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   5207\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   5208\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   5209\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   5342\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   5343\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 5344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdrop(\n\u001b[1;32m   5345\u001b[0m         labels\u001b[38;5;241m=\u001b[39mlabels,\n\u001b[1;32m   5346\u001b[0m         axis\u001b[38;5;241m=\u001b[39maxis,\n\u001b[1;32m   5347\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[1;32m   5348\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m   5349\u001b[0m         level\u001b[38;5;241m=\u001b[39mlevel,\n\u001b[1;32m   5350\u001b[0m         inplace\u001b[38;5;241m=\u001b[39minplace,\n\u001b[1;32m   5351\u001b[0m         errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[1;32m   5352\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/generic.py:4711\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4709\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4710\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4711\u001b[0m         obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_drop_axis(labels, axis, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4713\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4714\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/generic.py:4753\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, only_slice)\u001b[0m\n\u001b[1;32m   4751\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4752\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4753\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4754\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4756\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4757\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/pandas/core/indexes/base.py:7000\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6998\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6999\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 7000\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlabels[mask]\u001b[38;5;241m.\u001b[39mtolist()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   7001\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   7002\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: '[15879] not found in axis'"
     ]
    }
   ],
   "source": [
    "accepted_prompts = pd.DataFrame(columns=['context', 'prompt'])\n",
    "for i in range(13):\n",
    "    prompt_sample = pd.read_csv(current_dir + '/prompts_'+str(i+1)+'.csv')\n",
    "    accepted_prompts = pd.concat([accepted_prompts, prompt_sample])\n",
    "\n",
    "idxlst = get_index_list(accepted_prompts, emo_df_lst)\n",
    "\n",
    "print(idxlst)\n",
    "\n",
    "print(len(accepted_prompts))\n",
    "\n",
    "#remove_accepted_convos()\n",
    "\n",
    "print(len(red_emo_prompt_df))\n",
    "\n",
    "red_emo_prompt_df = remove_accepted_convos(idxlst,red_emo_prompt_df)\n",
    "\n",
    "print(len(red_emo_prompt_df))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "306393f0-d720-4b97-8ce7-d6512e6ae62d",
   "metadata": {},
   "source": [
    "### Check the human accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "80ce65df-4bb3-4af6-b480-2f431c2df5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.19\n",
      "0.87\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import CEM as cem\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "human_df = pd.read_excel('group_1_final_ev.xlsx.ods', engine = 'odf')\n",
    "human_df\n",
    "\n",
    "person = \"Reviewer #1\"\n",
    "\n",
    "\n",
    "acc = accuracy_score(human_df['ROUND'], human_df[person])\n",
    "\n",
    "print(acc)\n",
    "\n",
    "\n",
    "human_df['ROUND_BINARY'] = human_df.apply(lambda x: 1 if (x['ROUND'] == 2 or x['ROUND'] == 1)  else 2, axis = 1)\n",
    "human_df['ROUND_BINARY'] = human_df.apply(lambda x: 1 if (x['ROUND'] == 2 or x['ROUND'] == 1)  else 2, axis = 1)\n",
    "\n",
    "human_df[person + '_BINARY'] = human_df.apply(lambda x: 1 if (x[person] == 2 or x[person] == 1)  else 2, axis = 1)\n",
    "\n",
    "acc = accuracy_score(human_df['ROUND_BINARY'], human_df[person + '_BINARY'])\n",
    "print(acc)\n",
    "human_df\n",
    "\n",
    "human_df.to_csv('human_binary.csv', index = False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6a5f1da-1cf7-4d4c-aa0b-cb23346f1221",
   "metadata": {},
   "source": [
    "### Turn a dataset to binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "216c1324-e1bf-426a-9616-7b115bd7e5d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges_all_no_emo.csv'\n",
    "test_database_dir = '/processed_databases/EmpatheticExchanges/test.csv'\n",
    "\n",
    "train_database_dir = '/processed_databases/EmpatheticExchanges/'\n",
    "trainFile = current_dir + train_database_dir + 'EmpatheticExchanges_train.csv'\n",
    "testFile = current_dir + train_database_dir + 'EmpatheticExchanges_test.csv'\n",
    "df_train = pd.read_csv(trainFile)\n",
    "df_test = pd.read_csv(testFile)\n",
    "\n",
    "\n",
    "df_train['empathy_red'] = df_train.apply(lambda x: 2 if (x['empathy'] == 3 or x['empathy'] == 2)  else 1, axis = 1)\n",
    "df_train = df_train.drop(columns=['empathy'])\n",
    "df_train = df_train.rename(columns={\"empathy_red\": \"empathy\"})\n",
    "\n",
    "df_test['empathy_red'] = df_test.apply(lambda x: 2 if (x['empathy'] == 3 or x['empathy'] == 2)  else 1, axis = 1)\n",
    "df_test = df_test.drop(columns=['empathy'])\n",
    "df_test = df_test.rename(columns={\"empathy_red\": \"empathy\"})\n",
    "\n",
    "df_test.to_csv(current_dir + train_database_dir + 'EmpatheticExchanges_test_binary.csv', index = False)\n",
    "df_train.to_csv(current_dir + train_database_dir + 'EmpatheticExchanges_train_binary.csv', index = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6e6af5-eccc-4101-b0f9-cabe72046a0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
