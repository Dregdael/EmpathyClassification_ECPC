{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99a6b6c6-ecfc-4923-8b2f-7c1bb9d48125",
   "metadata": {},
   "source": [
    "# DEMO for empathy classification\n",
    "\n",
    "In this demo, we classify the empathy in text exchanges. \n",
    "\n",
    "We provide the most supported pattern for the classification of the exchange. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c367a65a-8f57-4dcd-8e31-f8b45938155d",
   "metadata": {},
   "source": [
    "# Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c241feda-8334-4a31-98e6-fc64620acb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import torch\n",
    "import os\n",
    "import sys\n",
    "import random \n",
    "import re\n",
    "#import classifier\n",
    "from PBC4cip import PBC4cip\n",
    "from PBC4cip.core.Evaluation import obtainAUCMulticlass\n",
    "from PBC4cip.core.Helpers import get_col_dist, get_idx_val\n",
    "from PBC4cip.core import Dataset as pbcDataset\n",
    "\n",
    "\n",
    "#utilities for database management\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "import train_classifier as trainer\n",
    "import test_classifier as tester\n",
    "import database_processing_package as data_processer\n",
    "\n",
    "#relevant classifiers for annotating exchange feature\n",
    "from classifiers.empathetic_intent import intent_prediction as ip\n",
    "from classifiers.sentiment import sentiment_prediction as sp\n",
    "from classifiers.epitome_mechanisms import epitome_predictor as epitome\n",
    "from classifiers.nrc_vad_lexicon import lexicon_analysis as lexicon\n",
    "from classifiers.course_grained_emotion import pretrained_32emotions as em32\n",
    "from classifiers.course_grained_emotion import emotion_reductor as em_red\n",
    "import database_processing_package as data_processer\n",
    "\n",
    "from spellchecker import SpellChecker\n",
    "from time import sleep\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f28688-b0f0-42c8-b1e8-f39fe6b0d959",
   "metadata": {},
   "source": [
    "### Load main classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0b8dd876-8b08-402b-916c-5d1386a271a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for the model: \n",
      "s_negative s_neutral s_positive l_negative l_neutral l_positive predictions_ER valence_speaker arousal_speaker dominance_speaker valence_listener arousal_listener dominance_listener s_word_len l_word_len agreeing acknowledging encouraging consoling sympathizing suggesting questioning wishing neutral mimicry "
     ]
    }
   ],
   "source": [
    "#Relevant directories\n",
    "current_dir = os.getcwd() #get directory of the repository\n",
    "\n",
    "#Database\n",
    "database_dir = '/processed_databases/EmpatheticExchanges/EmpatheticExchanges.csv'\n",
    "test_database_dir = '/processed_databases/EmpatheticExchanges/test.csv'\n",
    "database = pd.read_csv(current_dir + database_dir)\n",
    "test_db = pd.read_csv(current_dir + test_database_dir)\n",
    "\n",
    "#Select an appropriate classification model in the Experiments folder\n",
    "#number_of_model =90 #The number of the experiment for the model of interest\n",
    "\n",
    "number_of_model = 104 #Best performing model without exchange number (broader pattern recognition)\n",
    "model_directory = current_dir + '/Experiments/outputs/Experiment '+ str(number_of_model) + '/' + 'trained_pbc4cip.sav'\n",
    "pbc = pickle.load(open(model_directory, 'rb'))\n",
    "\n",
    "#Select features relevant for the model\n",
    "att_lst = [attribute[0] for attribute in pbc.dataset.Attributes]\n",
    "print('Features for the model: ')\n",
    "for attribute in att_lst:\n",
    "    print(attribute, end = ' ')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b8d488-f425-473a-9919-cd2878c5e726",
   "metadata": {},
   "source": [
    "### Load supplementary classification models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b9a94c89-a47c-4ed2-be22-0f8fcac352d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_flag = 0\n",
    "ex_num_flag = 0\n",
    "epitome_flag = 0\n",
    "vad_flag = 0\n",
    "intent_flag = 0\n",
    "mimicry_flag = 0\n",
    "length_flag = 1 #always on\n",
    "emo_labels_flag = 0\n",
    "\n",
    "\n",
    "#get the classifiers necessary for processing the response\n",
    "if {'s_negative','s_neutral','s_positive','l_negative','l_neutral','l_positive'} & set(att_lst): \n",
    "    sentiment_flag = 1\n",
    "    empIntSubDir = './classifiers/empathetic_intent/'\n",
    "    sent_model, sent_tokenzr = sp.loadSentimentModel() #get model and tokenizer\n",
    "if {'exchange_number'} & set(att_lst): \n",
    "    ex_num_flag = 1\n",
    "if {'predictions_ER','predictions_IP','predictions_EX'} & set(att_lst): \n",
    "    epitome_flag = 1\n",
    "    epitome_empathy_classifier = epitome.load_epitome_classifier('classifiers/epitome_mechanisms/trained_models')\n",
    "if {'valence_speaker','arousal_speaker','dominance_speaker','valence_listener','arousal_listener','dominance_listener'} & set(att_lst): \n",
    "    vad_flag = 1\n",
    "    lexicon_df, wnl, stp_wrds = lexicon.setup_lexicon('classifiers/nrc_vad_lexicon/BipolarScale/NRC-VAD-Lexicon.txt')\n",
    "if {'agreeing','acknowledging','encouraging','consoling','sympathizing',\n",
    "    'suggesting','questioning','wishing','neutral'} & set(att_lst): \n",
    "    intent_flag = 1\n",
    "    empIntSubDir = './classifiers/empathetic_intent/'\n",
    "    model_intent,tokenizer_intent,device = ip.loadModelTokenizerAndDevice(empIntSubDir) #get model and parameters\n",
    "if {'mimicry'} & set(att_lst): \n",
    "    mimicry_flag = 1\n",
    "    lexicon_df, wnl, stp_wrds = lexicon.setup_lexicon('classifiers/nrc_vad_lexicon/BipolarScale/NRC-VAD-Lexicon.txt')\n",
    "if {'speaker_emotion','listener_emotion'} & set(att_lst):\n",
    "    emo_labels_flag = 1\n",
    "    emo32_model, emo32_tokenzr = em32.load32EmotionsModel()\n",
    "\n",
    "flag_array = [sentiment_flag,ex_num_flag,epitome_flag,vad_flag,intent_flag,mimicry_flag,length_flag,emo_labels_flag]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "827b03cb-42ef-4e6d-82f4-50c10439eb56",
   "metadata": {},
   "source": [
    "### Function to classify exchange empathy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e29b3b0a-9d53-4d6e-ab89-ad87d8bd8f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Main processing function\n",
    "\n",
    "def predict_exchange_empathy(classifier, flag_array,ex_num, att_lst, speaker_utterance, listener_utterance):\n",
    "    \n",
    "    #Turn an string exchange into a dataframe\n",
    "    dummy_dic = {feature: [0] for feature in att_lst}\n",
    "    exchange_df = pd.DataFrame.from_dict(dummy_dic)\n",
    "    exchange_df['speaker_utterance'] = speaker_utterance\n",
    "    exchange_df['listener_utterance'] = listener_utterance\n",
    "\n",
    "    #Add the features to the exchange dataframe according to the ones used by model. We use the same functions as the experiments, which is why we do everything through dataframes\n",
    "    if flag_array[0] == 1: \n",
    "        #get sentiment\n",
    "        exchange_df['speaker_sentiment'] = exchange_df.apply(data_processer.get_sentiment_probabilities,axis = 1, args = (sent_model,sent_tokenzr,'speaker_utterance')) \n",
    "        exchange_df[['s_negative','s_neutral', 's_positive']] = pd.DataFrame(exchange_df.speaker_sentiment.tolist(),index = exchange_df.index)\n",
    "        exchange_df['listener_sentiment'] = exchange_df.apply(data_processer.get_sentiment_probabilities,axis = 1, args = (sent_model,sent_tokenzr,'listener_utterance')) \n",
    "        exchange_df[['l_negative','l_neutral', 'l_positive']] = pd.DataFrame(exchange_df.listener_sentiment.tolist(),index = exchange_df.index)\n",
    "        exchange_df = exchange_df.drop(columns=['speaker_sentiment','listener_sentiment'])\n",
    "    if flag_array[1] == 1:\n",
    "        #set exchange number to the one we provide\n",
    "        exchange_df['exchange_number'] = ex_num\n",
    "    if flag_array[2] == 1:\n",
    "        #get epitome communication mechanisms\n",
    "        exchange_df = epitome.classify_epitome_values(epitome_empathy_classifier, exchange_df)\n",
    "    if flag_array[3] == 1:\n",
    "        #get VAD vectors\n",
    "        exchange_df['vad_speaker'] = exchange_df['speaker_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "        exchange_df['vad_listener'] = exchange_df['listener_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "        exchange_df[['valence_speaker','arousal_speaker','dominance_speaker']] = pd.DataFrame(exchange_df.vad_speaker.tolist(),index = exchange_df.index)\n",
    "        exchange_df[['valence_listener','arousal_listener','dominance_listener']] = pd.DataFrame(exchange_df.vad_listener.tolist(),index = exchange_df.index)\n",
    "        exchange_df = exchange_df.drop(columns = ['vad_speaker','vad_listener'])\n",
    "    if flag_array[4] == 1:\n",
    "        #get word lengths\n",
    "        exchange_df['s_word_len'] = exchange_df['speaker_utterance'].apply(data_processer.get_word_len) \n",
    "        exchange_df['l_word_len'] = exchange_df['listener_utterance'].apply(data_processer.get_word_len) \n",
    "    if flag_array[5] == 1: \n",
    "        #get intent\n",
    "        exchange_df['utterance'] = exchange_df['listener_utterance']\n",
    "        exchange_df['is_response'] = 1\n",
    "        exchange_df['empathetic_intent'] = exchange_df.apply(data_processer.get_emp_intent_probabilities, axis=1, args = (model_intent,tokenizer_intent,device,'listener_utterance'))\n",
    "        exchange_df[data_processer.intent_labels] = pd.DataFrame(exchange_df.empathetic_intent.tolist(),index = exchange_df.index)\n",
    "        exchange_df = exchange_df.drop(columns=['empathetic_intent','utterance','is_response'])\n",
    "    if  flag_array[6] == 1:\n",
    "        if(flag_array[3] == 1):\n",
    "            #get the emotional similarity, if it is more than 0.7 set mimicry to 1\n",
    "            exchange_df['emotional_similarity'] = exchange_df.apply(data_processer.get_cosine_similarity,axis = 1) \n",
    "            exchange_df['mimicry'] = exchange_df.apply(lambda x: 1 if x['emotional_similarity'] > 0.7 else 0, axis = 1)\n",
    "            exchange_df = exchange_df.drop(columns = ['emotional_similarity'])\n",
    "        else: \n",
    "            #get emotional mimicry by first computing VAD vectors, since these are not used by the classifier, they are subsequently deleted. \n",
    "            exchange_df['vad_speaker'] = exchange_df['speaker_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "            exchange_df['vad_listener'] = exchange_df['listener_utterance'].apply(lexicon.get_avg_vad, args = (lexicon_df,wnl,stp_wrds)) \n",
    "            exchange_df[['valence_speaker','arousal_speaker','dominance_speaker']] = pd.DataFrame(exchange_df.vad_speaker.tolist(),index = exchange_df.index)\n",
    "            exchange_df[['valence_listener','arousal_listener','dominance_listener']] = pd.DataFrame(exchange_df.vad_listener.tolist(),index = exchange_df.index)\n",
    "            exchange_df = exchange_df.drop(columns = ['vad_speaker','vad_listener'])                \n",
    "            exchange_df['emotional_similarity'] = exchange_df.apply(data_processer.get_cosine_similarity,axis = 1) \n",
    "            exchange_df['mimicry'] = exchange_df.apply(lambda x: 1 if x['emotional_similarity'] > 0.7 else 0, axis = 1)\n",
    "            exchange_df = exchange_df.drop(columns =  ['valence_speaker','arousal_speaker','dominance_speaker','valence_listener','arousal_listener','dominance_listener','emotional_similarity'])\n",
    "        exchange_df['mimicry'] = exchange_df['mimicry'].astype('category')\n",
    "        exchange_df['mimicry'] = exchange_df['mimicry'].astype('string')\n",
    "    if flag_array[7] == 1:\n",
    "        #get emotion labels\n",
    "        exchange_df['speaker_emotion'] = exchange_df.apply(data_processer.get_emotion_label,axis = 1, args = (emo32_model,emo32_tokenzr,'speaker_utterance')) \n",
    "        exchange_df['listener_emotion'] = exchange_df.apply(data_processer.get_emotion_label,axis = 1, args = (emo32_model,emo32_tokenzr,'listener_utterance')) \n",
    "        exchange_df = em_red.reduce_emotion_labels_to_8('speaker_emotion',exchange_df)\n",
    "        exchange_df = em_red.reduce_emotion_labels_to_8('listener_emotion',exchange_df)\n",
    "\n",
    "    exchange_df = exchange_df[att_lst] #Feature order must match! \n",
    "    #Predict empathy\n",
    "    empathy_prediction = classifier.predict(exchange_df) \n",
    "\n",
    "    #output exchange dataframe and prediction\n",
    "    return exchange_df, empathy_prediction[-1] + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "decf06ed-8d87-48a3-8204-bcbc6cff5926",
   "metadata": {},
   "source": [
    "### Function to recommend a response based on features of the exchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "16207574-f633-4714-810e-c962cb7ab889",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fix_mimicry(list):\n",
    "    #This just changes the mimicry fature to have a 'binary' descriptor instead of a list to make it hashable\n",
    "    if(('mimicry', ['0', '1']) in list):\n",
    "        mimicry_index = list.index(('mimicry', ['0', '1']))\n",
    "        list[mimicry_index] = ('mimicry', 'binary')\n",
    "    return list\n",
    "\n",
    "def is_greater_than(feature_name, pattern_items):\n",
    "    #We use this function to get if the feature in a pattern implies an increase of that feature\n",
    "    for item in pattern_items:\n",
    "        if feature_name in str(item) and '>' in str(item):\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def recursive_search(search_control, intersections,items,role):\n",
    "    #print('recursive')\n",
    "    \n",
    "    #start the search\n",
    "    if search_control == 0:\n",
    "        if len(intersections[0]) > 0:\n",
    "            return recursive_search(1,intersections,items,role)\n",
    "        elif len(intersections[1]) > 0:\n",
    "            return recursive_search(2,intersections,items,role)\n",
    "        elif len(intersections[2]) > 0:\n",
    "            return recursive_search(3,intersections,items,role)            \n",
    "        elif len(intersections[3]) > 0:\n",
    "            return recursive_search(4,intersections,items,role)\n",
    "        elif len(intersections[4]) > 0:\n",
    "            return recursive_search(5,intersections,items,role)\n",
    "        elif len(intersections[5]) > 0:\n",
    "            return recursive_search(6,intersections,items,role)\n",
    "        else:\n",
    "            #print('NO FEATURES AVAILABLE')\n",
    "            return 'ERROR: No features available for this purpose'\n",
    "    #The gist of this function is that it searches for features in the most representative pattern of a class of empathy. If it finds it and the pattern says that that feature is higher (>), we make a recommendation to increase that feature in the response\n",
    "    if search_control == 1:\n",
    "        #print('VAD')\n",
    "        if ('valence_listener' in intersections[0]) and (is_greater_than('valence_listener', items)):\n",
    "            #return 'Maybe we should be more positive!'\n",
    "            return \"Suggestion: Increase valence\"\n",
    "        elif 'arousal_listener' in intersections[0] and (is_greater_than('arousal_listener', items)):\n",
    "            #return 'How about we say our feelings with more intensity!'\n",
    "            #return \"Suggestion: Increase arousal\"\n",
    "            return \"Suggestion: Maybe we should focus on the feelings of the other person!\" \n",
    "        elif 'arousal_listener' in intersections[0] and (is_greater_than('arousal_listener', items)):\n",
    "            #return \"Remember \"+ role +\" confidence is important!\"\n",
    "            return \"Suggestion: \"+ role +\" should display more confidence (dominance)\"\n",
    "        else:\n",
    "            #print('NO VAD')\n",
    "            return recursive_search(search_control+1, intersections,items,role)\n",
    "    elif search_control == 2:\n",
    "        #print('Intent')\n",
    "        if ('questioning' in intersections[1]) and (is_greater_than('questioning', items)):\n",
    "            #return \"Hey \"+role+\" why not ask them a question? I also want to know more\"\n",
    "            return \"Suggestion: \" + str(role) + \", I think you should ask them a question about what they say.\"\n",
    "        elif ('acknowledging' in intersections[1]) and (is_greater_than('acknowledging', items)):\n",
    "            #print(items)\n",
    "            if ('s_positive <' in str(items)) or ('s_negative >' in str(items)) or ('valence_speaker <' in str(items)):\n",
    "                return \"Suggestion: Acknowledge their negative feelings, \" + role\n",
    "                #return \"Oh no, Have you ever been in a similar situation \"+ role+\"?\"\n",
    "            else:\n",
    "                return \"Suggestion: Acknowledge their positive feelings, \" + role\n",
    "                #return \"Oh nice, Have you ever been in a similar situation \"+ role+\"?\"\n",
    "        elif ('agreeing' in intersections[1]) and (is_greater_than('agreeing', items)):\n",
    "            return \"Suggestion: I think they were looking for agreement \"+role+\".\"\n",
    "            #return \"I think they were looking for agreement \"+role+\".\"\n",
    "        elif ('encouraging' in intersections[1]) and (is_greater_than('encouraging', items)):\n",
    "            return \"Suggestion: My sensors say that we should encourage them about their feelings \"+role+\"\"\n",
    "            #return \"My sensors say that we should encourage them about their feelings \"+role+\"?\"\n",
    "        elif ('consoling' in intersections[1]) and (is_greater_than('consoling', items)):\n",
    "            return \"Suggestion: Consolation should be provided\"\n",
    "            #return \"Oh no \"+role+\" Maybe we could say something to cheer them up!\"       \n",
    "        elif ('suggesting' in intersections[1]) and (is_greater_than('suggesting', items)):\n",
    "            return \"Suggestion: Suggest something they could do\"\n",
    "            #return 'What do you think they should do?'\n",
    "        elif ('wishing' in intersections[1]) and (is_greater_than('wishing', items)):\n",
    "            return \"Suggestion: Humans wish eachother good things in these situations\"\n",
    "            #return \"I hear humans wish eachother good things in these situations \"+role+\". Why don't you give it a try?\"\n",
    "        elif ('sympathizing' in intersections[1]) and (is_greater_than('sympathizing', items)):\n",
    "            return \"Suggestion: Respond with sympathy\"\n",
    "            #return 'Oh, I feel bad for them. Do you feel like that too?'  \n",
    "        else:\n",
    "            return recursive_search(search_control+1, intersections,items,role)\n",
    "    elif search_control == 3:\n",
    "        #print('Sentiment')\n",
    "        if ('l_positive' in intersections[1]) and (is_greater_than('l_positive', items)):\n",
    "            return \"Suggestion: Be more positive\"\n",
    "            #return 'Hmm, maybe we should be more positive'\n",
    "        elif ('l_negative' in intersections[2]) and (is_greater_than('l_negative', items)):\n",
    "            #return \"Oh, that's bad. Don't you agree \"+role+\"?\"\n",
    "            return \"Suggestion: Acknowledge their negative feelings\"\n",
    "        else:\n",
    "            return recursive_search(search_control+1, intersections,items,role)\n",
    "    elif search_control == 4:\n",
    "        #print('epitome')\n",
    "        if ('predictions_ER' in intersections[3]) and (is_greater_than('predictions_ER', items)):\n",
    "            return 'How about we say our feelings with more intensity!'\n",
    "        elif ('predictions_EX' in intersections[3]) and (is_greater_than('predictions_EX', items)):\n",
    "            return \"Hey \"+role+\" why not ask them a question? I also want to know more\"\n",
    "        elif ('predictions_IP' in intersections[3]) and (is_greater_than('predictions_IP', items)):\n",
    "            return \"Do you understand what they mean?\"   \n",
    "        else:\n",
    "            return recursive_search(search_control+1, intersections,items,role)\n",
    "    elif search_control == 5:\n",
    "        if len(intersections[4]) > 0:\n",
    "            return 'Do you feel the same way?'\n",
    "        else:\n",
    "            return recursive_search(search_control+1, intersections,items,role)\n",
    "    elif search_control == 6:\n",
    "        if len(intersections[5]) > 0:\n",
    "            return 'Maybe you should elaborate more'\n",
    "        else:\n",
    "            return recursive_search(search_control+1, intersections,items,role)\n",
    "    else:\n",
    "        #print('NO FEATURES AVAILABLE')\n",
    "        return 'ERROR'\n",
    "\n",
    "\n",
    "def compute_feature_intersections(feature_names):\n",
    "    #Features from the 'listener' role\n",
    "    intent_features = ['agreeing', 'acknowledging', 'encouraging', 'consoling', 'sympathizing', 'suggesting', 'questioning', 'wishing']\n",
    "    sentiment_features = ['l_negative', 'l_neutral', 'l_positive']\n",
    "    epitome_features = ['predictions_ER', 'predictions_EX', 'predictions_IP']\n",
    "    length_features = ['l_word_len']\n",
    "    vad_features = ['valence_listener', 'arousal_listener', 'dominance_listener']\n",
    "    mimicry_features = ['mimicry']\n",
    "\n",
    "    intent_intersection = set(intent_features).intersection(set(feature_names))\n",
    "    vad_intersection = set(vad_features).intersection(set(feature_names))\n",
    "    sentiment_intersection = set(sentiment_features).intersection(set(feature_names))\n",
    "    epitome_intersection = set(sentiment_features).intersection(set(feature_names))\n",
    "    mimicry_intersection = set(mimicry_features).intersection(set(feature_names))\n",
    "    len_intersection = set(length_features).intersection(set(feature_names))\n",
    "\n",
    "    intersection_arr = [vad_intersection,intent_intersection,sentiment_intersection,epitome_intersection,mimicry_intersection,len_intersection]\n",
    "    return intersection_arr\n",
    "    \n",
    "\n",
    "\n",
    "def get_recommentation(classifier, exchange_df,role):\n",
    "    #get most influential patterns\n",
    "    \n",
    "    emerging_patterns = classifier.EmergingPatterns #access the patterns mined by the classifier\n",
    "    pattern_list = [] #patterns that cover the exchange\n",
    "    for instance in exchange_df.to_numpy(): \n",
    "        for pattern in emerging_patterns:\n",
    "            if pattern.IsMatch(instance):\n",
    "                pattern_list.append(pattern)   \n",
    "    count_lst = [pattern.Counts for pattern in pattern_list]\n",
    "    count_arr = np.array(count_lst)\n",
    "    most_support_low = pattern_list[count_arr[:,0].argmax()] #Pattern that most supports the lowest class\n",
    "    most_support_mid = pattern_list[count_arr[:,1].argmax()] #Pattern that most supports the middle class\n",
    "    most_support_high = pattern_list[count_arr[:,2].argmax()] #Pattern that most supports the high class\n",
    "\n",
    "    #print(most_support_high)\n",
    "    \n",
    "    most_support_high_items = most_support_high.Items\n",
    "    most_support_mid_items = most_support_mid.Items\n",
    "    most_support_low_items = most_support_low.Items\n",
    "    \n",
    "    #get the features from most supported patterns\n",
    "    most_support_high_features = [items.Feature for items in most_support_high.Items]\n",
    "    most_support_mid_features = [items.Feature for items in most_support_mid.Items]\n",
    "    most_support_low_features =[items.Feature for items in most_support_low.Items]\n",
    "\n",
    "    most_support_high_features = fix_mimicry(most_support_high_features)\n",
    "    most_support_mid_features = fix_mimicry(most_support_mid_features)\n",
    "    most_support_low_features = fix_mimicry(most_support_low_features)\n",
    "\n",
    "\n",
    "    #Obtain the features that differenciate the low features from the others\n",
    "    features_only_on_low = set(most_support_low_features) - set(most_support_high_features) - set(most_support_mid_features) \n",
    "    features_only_on_mid = set(most_support_mid_features) - set(most_support_low_features)\n",
    "    features_only_on_high = set(most_support_high_features) - set(most_support_low_features)\n",
    "\n",
    "    #print(most_support_high)\n",
    "    #print(features_only_on_high)\n",
    "    \n",
    "    #get the names of the features on the class of interest\n",
    "    feature_names_high = [features[0] for features in features_only_on_high]\n",
    "    feature_names_mid = [features[0] for features in features_only_on_mid]\n",
    "    fearure_names_low = [features[0] for features in features_only_on_low]\n",
    "\n",
    "    #First, we try to improve empathy using the features from the pattern most representative of the high empathy class\n",
    "    intersections = compute_feature_intersections(feature_names_high)\n",
    "    response = recursive_search(0,intersections,most_support_high_items, str(role))\n",
    "    #print(type(response))\n",
    "    if 'ERROR' in response:\n",
    "        #if that fails, we try to get a response using the features from the middle empathy class\n",
    "        intersections = compute_feature_intersections(feature_names_mid)\n",
    "        response = recursive_search(0,intersections,most_support_mid_items,str(role))\n",
    "        if 'ERROR' in response:\n",
    "            #If that fails, we just give up (maybe we should try to do the reverse using the features on the low empathy class i.e. check if there are features we could reduce (<))\n",
    "            print('Maybe we should talk about something else')\n",
    "    \n",
    "    #print(response)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7912c64d-ce2e-475b-8e77-af84dc095140",
   "metadata": {},
   "source": [
    "### Function to judge an exchange and get a recommendation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "06bdf55e-6c7e-4b12-abda-cc45dc23ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def judge_exchange(classifier,flag_array, att_lst,speaker_utterance,listener_utterance,role):\n",
    "    processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst,speaker_utterance, listener_utterance)\n",
    "    print(f\"Empathy prediction for {role}: {pred}/3\")\n",
    "    if pred < 2: \n",
    "        print('Low empathy detected!')\n",
    "        recommendation = get_recommentation(pbc, processed_exchange,role)\n",
    "        print(f\"interjection by Haru: {recommendation}\")\n",
    "        #print(recommendation)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "def get_input():\n",
    "    bad_input_flag = True\n",
    "    while bad_input_flag:\n",
    "        utterance = input(\"Provide input: \")\n",
    "        if utterance.lower() == '':\n",
    "            print('Please provide valid input')\n",
    "        else:\n",
    "            bad_input_flag = False    \n",
    "    return utterance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60133a3e-af0a-45e3-a95b-8c15d1ae8047",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: Acknowledge their negative feelings, listener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "judge_exchange(pbc,flag_array,att_lst,'I hate when my wife and son are away from me', \"Oh ok. \",\"listener\")\n",
    "judge_exchange(pbc,flag_array,att_lst,'I hate when my wife and son are away from me', \"I've never been in that situation but that is understandable. \",\"listener\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "882c4847-da01-4ea1-91df-08ca06ba8d43",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5088618-fb00-4c0b-b2f0-4d091ce756c4",
   "metadata": {},
   "source": [
    "## Examples of inference and recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dde1d04-5fe6-4c4b-a439-ebca34d8c0ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: Suggest something they could do\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'finally got my house, I do not have to deal with apartment living anymore', \"apartments are ok\",\"listener\")\n",
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'finally got my house, I do not have to deal with apartment living anymore', \"apartments are ok, you shouldn't knock them\",\"listener\")\n",
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'finally got my house, I do not have to deal with apartment living anymore', \"That's great I love living in my apartment but I'm happy for you\",\"listener\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e16dbbf-eff2-4ac1-b316-892b89779d8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afacb06b-2ac1-4d72-ae27-50fc0162a102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: Acknowledge their positive feelings, listener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'I cannot wait for the newest Pokemon game, it looks amazing to me!', \"pokemon is just ok\",\"listener\")\n",
    "\n",
    "\n",
    "judge_exchange(pbc,flag_array,att_lst,'I cannot wait for the newest Pokemon game, it looks amazing to me!', \"Oh well it's not bad. I had fun with pokemon when I was 10\",\"listener\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ffde58-acde-4dea-8d2c-3e73e9707f3d",
   "metadata": {},
   "source": [
    "## Automatic conversation loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "327eb626-7772-4d41-9992-d50f1c170b55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker turn: I cannot wait for the newest Pokemon game, it looks amazing to me!\n",
      "Listener turn: pokemon is just ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: Acknowledge their positive feelings, listener\n",
      "Listener turn: Oh well it's not bad. I had fun with pokemon when I was 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n",
      "Speaker turn: I see your point, but I still think it is fun\n",
      "Speaker_empathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for speaker: 3/3\n",
      "Listener turn: Oh well it's not bad. I had fun with pokemon when I was 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n",
      "['I cannot wait for the newest Pokemon game, it looks amazing to me!', 'I see your point, but I still think it is fun']\n",
      "[\"Oh well it's not bad. I had fun with pokemon when I was 10\", \"Oh well it's not bad. I had fun with pokemon when I was 10\"]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "spkr = [\"I cannot wait for the newest Pokemon game, it looks amazing to me!\", \"I see your point, but I still think it is fun\",'abortsequence']\n",
    "lstnr = ['pokemon is just ok',\"Oh well it's not bad. I had fun with pokemon when I was 10\", \"I relate to that, I listen to old songs from my childhood\",'abortsequence']\n",
    "\n",
    "speaker_utterances = []\n",
    "listener_utterances = []\n",
    "\n",
    "conversation_end = False\n",
    "#For a short conversation \n",
    "for i in range(2):    \n",
    "    if i>0:\n",
    "        j = i\n",
    "        while not good_speaker:\n",
    "            prompt = spkr[j]\n",
    "            print(f\"Speaker turn: {prompt}\")\n",
    "            print('Speaker_empathy')\n",
    "            good_speaker = judge_exchange(pbc, flag_array, att_lst, listener_utterances[i-1],prompt,'speaker')\n",
    "            j = j+1\n",
    "            #judgement_on_speaker = False\n",
    "            #print(f'judgement on speaker {judgement_on_speaker}')\n",
    "    else:      \n",
    "        prompt = spkr[i]\n",
    "        print(f\"Speaker turn: {prompt}\")\n",
    "        if 'abortsequence' in prompt:\n",
    "            break\n",
    "        good_speaker = False    \n",
    "        \n",
    "    \n",
    "    \n",
    "    speaker_utterances.append(prompt) #We append the successful utterance to the record\n",
    "    good_listener = False\n",
    "    #Keep listener hostage while they do not provide empathetic responses\n",
    "    j = i\n",
    "    while not good_listener:\n",
    "        answer = lstnr[j]\n",
    "        print(f\"Listener turn: {answer}\")\n",
    "        if 'abortsequence' in answer:\n",
    "            break\n",
    "        good_listener = judge_exchange(pbc, flag_array, att_lst, speaker_utterances[i], answer,'listener')\n",
    "        j = j+1\n",
    "        #print(f\"Speaker: {speaker_utterances[i]}\")\n",
    "        #print(f\"Listener: {listener_utterances[i]}\")     \n",
    "    listener_utterances.append(answer)\n",
    "\n",
    "\n",
    "print(speaker_utterances)\n",
    "print(listener_utterances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dad3c7ca-add5-4495-a3ea-3d82d9ad0142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker turn: I cannot wait for the newest Pokemon game, it looks amazing to me!\n",
      "Listener turn: pokemon is just ok\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: Acknowledge their positive feelings, listener\n",
      "Listener turn: Oh well it's not bad. I had fun with pokemon when I was 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n",
      "3 1\n",
      "Speaker turn: I see your point, but I still think it is fun\n",
      "Speaker_empathy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for speaker: 3/3\n",
      "Listener turn: abortsequence\n",
      "3 2\n",
      "['I cannot wait for the newest Pokemon game, it looks amazing to me!', 'I see your point, but I still think it is fun']\n",
      "[\"Oh well it's not bad. I had fun with pokemon when I was 10\", 'abortsequence']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "spkr = [\"I cannot wait for the newest Pokemon game, it looks amazing to me!\", \"I see your point, but I still think it is fun\",'abortsequence']\n",
    "lstnr = ['pokemon is just ok',\"Oh well it's not bad. I had fun with pokemon when I was 10\", \"Yeah it was to me, maybe I should try the new one\",'abortsequence']\n",
    "\n",
    "speaker_utterances = []\n",
    "listener_utterances = []\n",
    "\n",
    "conversation_end = False\n",
    "#For a short conversation\n",
    "\n",
    "j = 0\n",
    "i = 0\n",
    "\n",
    "while not conversation_end:    \n",
    "    if j>0:\n",
    "        good_speaker = False    \n",
    "        while not good_speaker:\n",
    "            prompt = spkr[j]\n",
    "            print(f\"Speaker turn: {prompt}\")\n",
    "            print('Speaker_empathy')\n",
    "            good_speaker = judge_exchange(pbc, flag_array, att_lst, lstnr[i-1],prompt,'speaker')\n",
    "            j = j+1\n",
    "            if j + 1 >= len(spkr):\n",
    "                conversation_end = True\n",
    "            #judgement_on_speaker = False\n",
    "            #print(f'judgement on speaker {judgement_on_speaker}')\n",
    "    else:      \n",
    "        prompt = spkr[i]\n",
    "        print(f\"Speaker turn: {prompt}\")\n",
    "        if 'abortsequence' in prompt:\n",
    "            break\n",
    "        good_speaker = False    \n",
    "        if j + 1 >= len(spkr):\n",
    "            conversation_end = True\n",
    "        else:\n",
    "            j += 1        \n",
    "    speaker_utterances.append(prompt) #We append the successful utterance to the record\n",
    "    good_listener = False\n",
    "    #Keep listener hostage while they do not provide empathetic responses\n",
    "    while not good_listener:\n",
    "        answer = lstnr[i]\n",
    "        print(f\"Listener turn: {answer}\")\n",
    "        if 'abortsequence' in answer:\n",
    "            conversation_end = True\n",
    "            break\n",
    "        good_listener = judge_exchange(pbc, flag_array, att_lst, spkr[j], answer,'listener')\n",
    "        i = i+1\n",
    "        #print(f\"Speaker: {speaker_utterances[i]}\")\n",
    "        #print(f\"Listener: {listener_utterances[i]}\")     \n",
    "    listener_utterances.append(answer)\n",
    "    if i + 1 >= len(lstnr):\n",
    "        conversation_end = True\n",
    "    else:\n",
    "        i += 1\n",
    "    print(f'{i} {j}')\n",
    "        \n",
    "\n",
    "\n",
    "print(speaker_utterances)\n",
    "print(listener_utterances)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b77f6c87-f9cc-48d4-be62-7446f745bb74",
   "metadata": {},
   "source": [
    "## Conversation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a64ffdc2-b236-4dfd-af41-441612c69684",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speaker, "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m2\u001b[39m):    \n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSpeaker, \u001b[39m\u001b[38;5;124m\"\u001b[39m, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m     prompt \u001b[38;5;241m=\u001b[39m get_input()\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mabortsequence\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m prompt:\n\u001b[1;32m      8\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[6], line 15\u001b[0m, in \u001b[0;36mget_input\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m bad_input_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m bad_input_flag:\n\u001b[0;32m---> 15\u001b[0m     utterance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide input: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utterance\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m     17\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease provide valid input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "speaker_utterances = []\n",
    "listener_utterances = []\n",
    "#For a short conversation \n",
    "for i in range(2):    \n",
    "    print(\"Speaker, \", end = '')\n",
    "    prompt = get_input()\n",
    "    if 'abortsequence' in prompt:\n",
    "        break\n",
    "    speaker_utterances.append(prompt) \n",
    "    good_exchange = False\n",
    "    #Keep listener hostage while they do not provide empathetic responses\n",
    "    while not good_exchange:\n",
    "        print(\"Listener,  \", end = '')\n",
    "        answer = get_input()\n",
    "        if 'abortsequence' in answer:\n",
    "            break\n",
    "        listener_utterances.append(answer)\n",
    "        print(f\"Speaker: {speaker_utterances[i]}\")\n",
    "        print(f\"Listener: {listener_utterances[i]}\")\n",
    "        good_exchange = judge_exchange(pbc, flag_array, att_lst, speaker_utterances[i], listener_utterances[i],'listener')\n",
    "    if i>0:\n",
    "        judgement_on_speaker = judge_exchange(pbc, flag_array, att_lst, listener_utterances[i-1],speaker_utterances[i],'speaker')\n",
    "        #judgement_on_speaker = False\n",
    "        print(f'judgement on speaker {judgement_on_speaker}')\n",
    "\n",
    "print(speaker_utterances)\n",
    "print(listener_utterances)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b5b4c602-4df8-4137-9b4f-48e2367bcaeb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m             bad_input_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m    \n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m utterance \n\u001b[0;32m---> 11\u001b[0m utterance \u001b[38;5;241m=\u001b[39m get_input()\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(utterance)\n",
      "Cell \u001b[0;32mIn[13], line 4\u001b[0m, in \u001b[0;36mget_input\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m bad_input_flag \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m bad_input_flag:\n\u001b[0;32m----> 4\u001b[0m     utterance \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvide input: \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m utterance\u001b[38;5;241m.\u001b[39mlower() \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m      6\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPlease provide valid input\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/ipykernel/kernelbase.py:1262\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1260\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1261\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[0;32m-> 1262\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_input_request(\n\u001b[1;32m   1263\u001b[0m     \u001b[38;5;28mstr\u001b[39m(prompt),\n\u001b[1;32m   1264\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_ident[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   1265\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_parent(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mshell\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1266\u001b[0m     password\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m   1267\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/emp_det/lib/python3.12/site-packages/ipykernel/kernelbase.py:1305\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1303\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[1;32m   1304\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1306\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1307\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "def get_input():\n",
    "    bad_input_flag = True\n",
    "    while bad_input_flag:\n",
    "        utterance = input(\"Provide input: \")\n",
    "        if utterance.lower() == '':\n",
    "            print('Please provide valid input')\n",
    "        else:\n",
    "            bad_input_flag = False    \n",
    "    return utterance \n",
    "\n",
    "utterance = get_input()\n",
    "\n",
    "print(utterance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9638d006-9e16-4f10-91c4-856fa01bc3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'How are you?', \"Doing pretty good, how about yourself?\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"I'm doing ok, just had a dental implant done\", \"Oh, ouch, that must have been pretty painful\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yeah, It was. But not as bad as you would think\", \"Great to hear, and now you have a shiny new tooth!\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yes! That makes it all worth it in the end\", \"For sure, despite the bad you get something great out of it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d33065c-219e-496c-ab91-ee1e8273834a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "judge_exchange() missing 1 required positional argument: 'role'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m judge_exchange(pbc, flag_array, att_lst, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOh, ouch, that must have been pretty painful\u001b[39m\u001b[38;5;124m\"\u001b[39m,  \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYeah, It was. But not as bad as you would think\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: judge_exchange() missing 1 required positional argument: 'role'"
     ]
    }
   ],
   "source": [
    "judge_exchange(pbc, flag_array, att_lst, \"Oh, ouch, that must have been pretty painful\",  \"Yeah, It was. But not as bad as you would think\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4dbab16d-7ffc-4c51-92d6-1fc4adcedae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'A co-worker of mine got a promotion over me.',\n",
       " 'I almost stepped on a snake today.',\n",
       " 'I applied for a job last week',\n",
       " 'I ate a whole pack of cookies',\n",
       " \"I can't wait for this halloween. I have the cutest theme for my kids\",\n",
       " 'I cannot wait for the new super smash bros for the nintendo switch',\n",
       " 'I enjoy working on and driving my old truck.',\n",
       " \"I forgot to get my son a bag of chips from the dollar store when I went out today - especially since I told him I'd pick up some on my way home.\",\n",
       " 'I found out that I was one of the top performers in the Mid-South district for my job! I knew I could do it!',\n",
       " 'I found out that my wife is pregnant today.',\n",
       " 'I have done lots of research for an interview this week',\n",
       " 'I just witnessed someone steal from an old woman walking across the street. Boils my blood!',\n",
       " \"I lost a job I had for many years. I wasn't sure what I would do_comma_ but I felt things would work out\",\n",
       " 'I ordered McDonalds today on UberEats. It was terrible.',\n",
       " \"I received an A on my final that I didn't even study for!!\",\n",
       " 'I remember applying for my job in the government. I felt pretty good about it!',\n",
       " 'I saw a giant flying roach on the front porch.',\n",
       " 'I spent hours reviewing notes and job materials to prepare for some trials for a job that I had applied for. I was so ready_comma_ and I ended up getting the job!',\n",
       " 'I think my daughter is going to always love school. She practically runs there every day and its all she talks about',\n",
       " 'I was pretty unsure of myself when learning to ride a bike at 15',\n",
       " 'I went to register my daughter for school today and the place was empty!',\n",
       " \"It was a gorgeous morning today_comma_ the sun was shining as I walked my dogs and I'm still on summer holdiays.\",\n",
       " \"It's back to school time. I am a teacher and I spent time getting my classroom ready today.\",\n",
       " \"My fiance is having her bachelorette party. I'm excited for her.\",\n",
       " 'My neighbor returned my wallet today. I was so thankful.',\n",
       " \"Once I was working on a big project with a bunch of people and made a mistake. One of the other people working on the project covered for me even though they didn't need to.\",\n",
       " 'Once my husband surprised me on my anniversary with a really pretty necklace and a trip to a Bed and Breakfast. I was so suprised b/c he usually only takes me to dinner for our anniversary.',\n",
       " 'Once_comma_ I was walking home from work and it was late. My street was unusally quiet and there was a man walking quickly behind me. I was very scared. He ended up passing me but he whispered a nasty word as he walked past.',\n",
       " \"Shortly after I got married_comma_ my wife and I decided that we wanted to have kids. When we found out she was pregnant_comma_ we couldn't wait to find out if we were having a boy or a girl.\",\n",
       " 'Someone tried to steal the tailgate off of my truck last night.',\n",
       " \"Super sad today. It's the weekend pretty much and I have a hard time with loneliness on the weekends especially. I would prefer to skip over them during this time in my life.\",\n",
       " \"This one time it really bothered me when someone told me that I couldn't accomplish a task.\",\n",
       " 'Uber Eats did not even bring my order today! Customer sevice was being weird about a refund',\n",
       " \"Well_comma_ I've finally found my perfect restaurant/grocery store. I stopped by the other day and bought some food and couldn't have been more pleased with everything there!\",\n",
       " 'When we were deciding to move across the country i was really nervous about the whole idea of it. I almost got cold feet.',\n",
       " 'Won a gift voucher from a survey I completed online',\n",
       " 'i feel grail d',\n",
       " 'i loved taking care of my sisters pet',\n",
       " 'i really enjoy having pets. they bring a new life into an empty feeling house',\n",
       " 'i was pissed when i saw someone put a dent in my door',\n",
       " 'my cat vomited on my carpet',\n",
       " 'my friend told me a secret',\n",
       " 'snakes'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "candidates = []\n",
    "for i in database['prompt']:\n",
    "    if(len(database[database['prompt'] == i]) >= 4 ):\n",
    "        #print(database[database['prompt'] == i])\n",
    "        candidates.append(i)\n",
    "set(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f6a7ac-2798-4f10-af85-6cb4cb97547b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted empathy: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted empathy: 1\n",
      "Low empathy detected\n",
      "response formulated by Haru\n",
      "Suggestion: Acknowledge their negative feelings\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted empathy: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted empathy: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend pretty much and I have a hard time with loneliness on the weekends especially.', \"I am sorry. Maybe not focus as friday-sunday as the weekend_comma_ but as any other day. And do things you would normally do on other days.\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n",
    "\n",
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend and I have a hard time with loneliness on the weekends especially.', \"I love the weekends actually\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n",
    "\n",
    "\n",
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend and I have a hard time with loneliness on the weekends especially.', \"Sorry to hear you are feeling lonely. But don't worry I am your friend\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n",
    "\n",
    "processed_exchange, pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'Super sad today. It is the weekend pretty much and I have a hard time with loneliness on the weekends especially.', \"Sorry to hear that, maybe you should go join a club to meet new people\")\n",
    "print(f\"Predicted empathy: {pred}\")\n",
    "if pred < 2: \n",
    "    print('Low empathy detected')\n",
    "    print('response formulated by Haru')\n",
    "    recommendation = get_recommentation(pbc, processed_exchange, 'listener')\n",
    "    print(recommendation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "86a73bf1-fff0-40cc-97ca-839dfc85513a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: My sensors say that we should encourage them about their feelings listener\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n",
      "Second exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n",
      "Third exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n",
      "Fourth exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n",
      "Fifth exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 1/3\n",
      "Low empathy detected!\n",
      "interjection by Haru: Suggestion: listener, I think you should ask them a question about what they say.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 2/3\n",
      "Six exchange\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empathy prediction for listener: 3/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "print(\"First exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"i loved taking care of my sisters pet\", \"Huh, is that so\", 'listener')\n",
    "judge_exchange(pbc,flag_array,att_lst,\"i loved taking care of my sisters pet\", \"It's cool that you loved that\", 'listener')\n",
    "print(\"Second exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"Yeah! I have loved animals since then especially dogs\", \"Dogs are very cute. Cats too\", \"listener\")\n",
    "print(\"Third exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"Oh my gosh yes. Cats are so fluffy and cuddly\", \"They are! I love petting them\", \"listener\")\n",
    "print(\"Fourth exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"You know i really enjoy having pets they bring a new life into an empty feeling house\", \"Yes I only have one cat. How about you?\", \"listener\")\n",
    "print(\"Fifth exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"we have a cat, a dog, a bunny, and a betta fish!\", \"Those are many pets\", \"listener\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"we have a cat, a dog, a bunny, and a betta fish!\", \"Those are many pets, how do you manage?\", \"listener\")\n",
    "print(\"Six exchange\")\n",
    "judge_exchange(pbc,flag_array,att_lst,\"It is a lot of work. But their little faces are so worth it\", \"Yes they are I bet you feel proud\", \"listener\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "2e71b635-d07d-414b-8fe2-d2f0d56a011b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, 'At the time there was a friend that told me that i could not jump over him_comma_ then i jumped over him.', \"Neat\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"I'm doing ok, just had a dental implant done\", \"Oh, ouch, that must have been pretty painful\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yeah, It was. But not as bad as you would think\", \"Great to hear, and now you have a shiny new tooth!\")\n",
    "processed_exchange, y_pred  = predict_exchange_empathy(pbc, flag_array, 1, att_lst, \"Yes! That makes it all worth it in the end\", \"For sure, despite the bad you get something great out of it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7856afa1-792f-4613-b316-1079451b71fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
